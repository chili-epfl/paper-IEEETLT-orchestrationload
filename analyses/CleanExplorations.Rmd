---
title: "Towards a New PCA/FA Method"
output:
  html_document: default
  pdf_document:
    keep_tex: yes
---

# Load clean/preprocessed data

The script assumes that you will put the clean datafiles (sold separately) in ```./data/study1```, ```./data/study2```, etc

```{r, message=FALSE, warning=FALSE, echo=FALSE}
source("./lib/outliers.R")
# In order to enable comparison across different sessions (even for the same subject, things like tiredness can vary the eye gaze patterns of a subject), we normalize the metrics by the average of the first three 10-second windows of the session (in which we assume similar, small load). Other possibilities for normalization: median value, scale/norm, coefficient of variance
source("./lib/loadIndex.R")

# Data for study 1
data1 <- get(load("./data/study1/study1ProcessedData.Rda"))
data1$Study <- 1

# Data for study 2
data2 <- get(load("./data/study2/study2ProcessedData.Rda"))
data2$Study <- 2

# Data for study 3
data3 <- get(load("./data/study3/study3ProcessedData.Rda"))
data3$Study <- 3

# Data for study 4
data4 <- get(load("./data/study4/study4ProcessedData.Rda"))
data4$Study <- 4

# Cleanup of study 4 data
names(data4)[7:10] <- c("Experimental","Social","Activity","Focus")
# from the preprocessing, the categorical values have too many levels, we fix it
data4$Experimental <- factor(data4$Experimental)
data4$Social <- factor(data4$Social)
data4$Activity <- factor(data4$Activity)
data4$Focus <- factor(data4$Focus)
data4$GroundTruth <- ifelse(data4$Experimental=="C2",1,ifelse(data4$Experimental=="C1",0,NA))
data4 <- data4[,-7] # Remove Experimental, now substituted by GroundTruth
data4 <- data4[!is.na(data4$value.Sac),] # remove samples where it was NA
#countOutliers(data4$value.Sac,coef = 5, method="iqr") # 5xinter-quartile range seems like a reasonable boundary for outliers
data4$value.Sac <- replaceOutliers(data4$value.Sac,valueNA = F,coef = 10, method="iqr") # We crop outliers beyond 10xinter-quartile range, giving them the value 5xIQR
data4$Social <- as.character(data4$Social)
data4$Activity <- as.character(data4$Activity)
data4$Focus <- as.character(data4$Focus)
data4$Subject <- "L"

# Cleanup of study 3 data
data3 <- data3[,-c(7:10,14:18)]
# Reorder the columns as in data4
data3 <- data3[,c(1:6,9,8,7,10)]
data3$GroundTruth <- ifelse(data3$session=="ISL2015NOVEL-Session3-eyetracking" | data3$session=="ISL2015NOVEL-Session4-eyetracking",1,ifelse(data3$session=="ISL2014BASELINE-Session1-eyetracking" | data3$session=="ISL2014BASELINE-Session2-eyetracking",0,NA))
data3 <- data3[!is.na(data3$value.Sac),] # remove samples where it was NA
#countOutliers(data3$value.Sac,coef = 5, method="iqr") # 5xinter-quartile range seems like a reasonable boundary for outliers
data3$value.Sac <- replaceOutliers(data3$value.Sac,valueNA = F,coef = 10, method="iqr") # We crop outliers beyond 10xinter-quartile range, giving them the value 5xIQR
data3$Social <- as.character(data3$Social)
data3$Activity <- as.character(data3$Activity)
data3$Focus <- as.character(data3$Focus)
# Solve inconsistency with other studies labels
data3[!is.na(data3$Focus) & data3$Focus=="PRJ","Focus"] <- "PROJ"
data3$Subject <- "W"


# Cleanup of study 2 data
data2 <- data2[,-c(7:10)]
# Reorder the columns as in data4
data2 <- data2[,c(1:6,9,8,7,10)]
data2$GroundTruth <- ifelse(data2$session=="DELANA-Session3-Novice-eyetracking",1,ifelse(data2$session=="DELANA-Session1-Expert-eyetracking" | data2$session=="DELANA-Session2-Expert-eyetracking",0,NA))
data2 <- data2[!is.na(data2$value.Sac),] # remove samples where it was NA
#countOutliers(data2$value.Sac,coef = 10, method="iqr") # 5xinter-quartile range seems like a reasonable boundary for outliers
data2$value.Sac <- replaceOutliers(data2$value.Sac,valueNA = F,coef = 10, method="iqr") # We crop outliers beyond 10xinter-quartile range, giving them the value 5xIQR
data2$Social <- as.character(data2$Social)
data2$Activity <- as.character(data2$Activity)
data2$Focus <- as.character(data2$Focus)
# Solve inconsistency with other studies labels
data2[!is.na(data2$Activity) & data2$Activity=="QUEST","Activity"] <- "QUE"
data2[!is.na(data2$Focus) & data2$Focus=="WHIT","Focus"] <- "WHI"
data2[data2$GroundTruth==1,"Subject"] <- "K"
data2[data2$GroundTruth==0,"Subject"] <- "K"

# Cleanup of study 1 data
data1 <- data1[,-c(7:9)]
# Reorder the columns as in data4
data1 <- data1[,c(1:6,8,7,9,10)]
data1$GroundTruth <- NA
data1 <- data1[!is.na(data1$value.Sac),] # remove samples where it was NA
#countOutliers(data1$value.Sac,coef = 10, method="iqr") # 5xinter-quartile range seems like a reasonable boundary for outliers
data1$value.Sac <- replaceOutliers(data1$value.Sac,valueNA = F,coef = 10, method="iqr") # We crop outliers beyond 10xinter-quartile range, giving them the value 5xIQR
levels(data1$Social) <- c("CLS","GRP")
data1$Social <- as.character(data1$Social)
data1$Activity <- as.character(data1$Activity)
data1$Focus <- as.character(data1$Focus)
data1$Subject <- "L"

# Join all studies' data
totaldata <- rbind(data1,data2,data3,data4)

# Calculate different normalizations of the eyetracking metrics, and the basic load indices
loaddata <- calculateLoadIndexAndNormalizations(totaldata,3:6,stablenorm = 3)

write.csv(loaddata,file="./data/loaddata-clean.csv")

```


## Using 1st PCA component

### Global data

```{r, message=FALSE, warning=FALSE}
# We calculate the PCA load index (score in the 1st PCA component)
library(FactoMineR)
pca.global = PCA(loaddata[, 3:6], scale.unit=TRUE, ncp=2, graph=F)
plot.PCA(pca.global, axes=c(1, 2), choix="var", title="PCA All studies")
# We add the PCA load index to our dataset
loaddata$PCALoad1 = pca.global$ind$coord[,1]
loaddata$PCALoad2 = pca.global$ind$coord[,2]


# clean up further the dataset, to keep only those samples for which we have process variables
behdata <- loaddata[!is.na(loaddata$Activity) & !is.na(loaddata$Social) & !is.na(loaddata$Focus) & !is.na(loaddata$GroundTruth),]

# We train an overall logistic regression model
lr1 <- glm(GroundTruth ~ Activity + Social + Focus + PCALoad1, family=binomial(link='logit'), data=behdata)
summary(lr1)
anova(lr1, test="Chisq") # PCA Load is a very significant predictor
1 - (lr1$deviance / lr1$null.deviance) # Pseudo-rsquared


```

### Study 2 (Study 1 in the new order)
```{r, message=FALSE, warning=FALSE}

# We train and evaluate for each study separately
# Study 2
behdata2 <- behdata[behdata$Study==2,]
# ... and we remove the samples with categorical variables that appear only very seldom
behdata2 <- behdata2[behdata2$Social!="GRP",]
behdata2$Social <- factor(behdata2$Social)
behdata2 <- behdata2[behdata2$Focus!="TEA",]
behdata2 <- behdata2[behdata2$Focus!="BAK",]
behdata2$Focus <- factor(behdata2$Focus)
lr2 <- glm(GroundTruth ~ Activity + Social + Focus + PCALoad1, family=binomial(link='logit'), data=behdata2) # The PCA load coefficient goes in the wrong direction!!!!???
summary(lr2)
anova(lr2, test="Chisq") # PCA Load is a very significant predictor
1 - (lr2$deviance / lr2$null.deviance) # Pseudo-rsquared



```



### Study 3 (Study 2 in the new order)

```{r, message=FALSE, warning=FALSE}

# Study 3
behdata3 <- behdata[behdata$Study==3,]
# ... and we remove the samples with categorical variables that appear only very seldom
behdata3 <- behdata3[behdata3$Activity!="DISC",]
behdata3$Activity <- factor(behdata3$Activity)
behdata3$Social <- factor(behdata3$Social)
behdata3 <- behdata3[behdata3$Focus!="TNG",]
behdata3 <- behdata3[behdata3$Focus!="RES",]
behdata3 <- behdata3[behdata3$Focus!="BAK",]
behdata3$Focus <- factor(behdata3$Focus)
lr3 <- glm(GroundTruth ~ Activity + Social + Focus + PCALoad1, family=binomial(link='logit'), data=behdata3) # The PCA load coefficient goes in the wrong direction!!!!???
summary(lr3)
anova(lr3, test="Chisq") # PCA Load is a very significant predictor
1 - (lr3$deviance / lr3$null.deviance) # Pseudo-rsquared



```



### Study 4 (Study 3 in the new order)

```{r, message=FALSE, warning=FALSE}

# Study 4
# Considering all episodes (not only extreme load ones)
behdata4 <- behdata[behdata$Study==4,]
# ... and we remove the samples with categorical variables that appear only very seldom
behdata4 <- behdata4[behdata4$Activity!="OFF",]
behdata4$Activity <- factor(behdata4$Activity)
behdata4 <- behdata4[behdata4$Social!="IND",]
behdata4$Social <- factor(behdata4$Social)
behdata4 <- behdata4[behdata4$Focus!="TCOMP",]
behdata4 <- behdata4[behdata4$Focus!="TD",]
behdata4$Focus <- factor(behdata4$Focus)

behdata4 <- within(behdata4, Focus <- relevel(Focus, ref = 2))


lr4 <- glm(GroundTruth ~ Activity + Social + Focus + PCALoad1, family=binomial(link='logit'), data=behdata4) # The PCA load coefficient goes in the right direction, but is not significant
summary(lr4)
anova(lr4, test="Chisq") # PCA Load is a very significant predictor
1 - (lr4$deviance / lr4$null.deviance) # Pseudo-rsquared=0.08


# Considering extreme load episodes only -- only 163 samples after cleaning!
behdata4b <- behdata[behdata$Study==4 & behdata$CoarseLoad %in% c(0,4),]
behdata4b <- behdata4b[behdata4b$Activity!="OFF",]
behdata4b$Activity <- factor(behdata4b$Activity)
behdata4b <- behdata4b[behdata4b$Social!="IND",]
behdata4b$Social <- factor(behdata4b$Social)
behdata4b <- behdata4b[behdata4b$Focus!="TCOMP",]
behdata4b <- behdata4b[behdata4b$Focus!="TD",]
behdata4b <- behdata4b[behdata4b$Focus!="TEA",]
behdata4b <- behdata4b[behdata4b$Focus!="TPAP",]
behdata4b$Focus <- factor(behdata4b$Focus)
lr4b <- glm(GroundTruth ~ Activity + Social + Focus + PCALoad1, family=binomial(link='logit'), data=behdata4b) # The PCA load coefficient goes in the right direction, but is not significant
summary(lr4b)
anova(lr4b, test="Chisq") # PCA Load is a very significant predictor

1 - (lr4b$deviance / lr4b$null.deviance) # Pseudo-rsquared=0.05




```

### Study 1 (Study 4 in the new order)
```{r, message=FALSE, warning=FALSE}
# We train and evaluate for each study separately
# Study 2
behdata1 <- loaddata[!is.na(loaddata$Activity) & !is.na(loaddata$Social) & !is.na(loaddata$Focus) & loaddata$Study==1,]
# ... and we remove the samples with categorical variables that appear only very seldom
behdata1$Activity <- factor(behdata1$Activity)
behdata1$Social <- factor(behdata1$Social)
behdata1 <- behdata1[behdata1$Focus!="W",]
behdata1 <- behdata1[behdata1$Focus!="M",]
behdata1 <- behdata1[behdata1$Focus!="RES",]
behdata1$Focus <- factor(behdata1$Focus)

behdata1 <- within(behdata1, Focus <- relevel(Focus, ref = 2))


# Assuming the PCALoad is a good indicator, what can we say about the load of the situation?
lm1 <- lm(PCALoad1 ~ Activity + Social + Focus, data=behdata1)
summary(lm1)
anova(lm1)

behdata1$session <- factor(behdata1$session)
lm1sess <- lm(PCALoad1 ~ Activity + Social + Focus + session, data=behdata1)
summary(lm1sess)
anova(lm1sess)

knitr::kable(
  summary(lm1sess)$coefficients, caption = 'Some caption.'
)
```


## Big table of linear models and significant effect sizes



### Study 2 (Study 1 in the new numbering)

```{r message=F, warning=F}


# Assuming the PCALoad is a good indicator, what can we say about the load of the situation?
lm2 <- lm(PCALoad1 ~ Activity + Social + Focus, data=behdata2)
summary(lm2)
anova(lm2)
# Significant trends in the linear model
s <- sd(behdata2$PCALoad1)
# Effect sizes of the significant coefficients
(summary(lm2)$coefficients[summary(lm2)$coefficients[,4]<0.05,1])/s


# Some trends/differences among teachers (not quite significant, tho)
lm2exp <-lm(PCALoad1 ~ Activity + Social + Focus, data=behdata2[behdata2$GroundTruth==0,])
summary(lm2exp)
anova(lm2exp)
# Effect sizes of the significant coefficients
(summary(lm2exp)$coefficients[summary(lm2exp)$coefficients[,4]<0.05,1])/s


lm2nov <-lm(PCALoad1 ~ Activity + Social + Focus, data=behdata2[behdata2$GroundTruth==1,])
summary(lm2nov)
anova(lm2nov)
# Effect sizes of the significant coefficients
(summary(lm2nov)$coefficients[summary(lm2nov)$coefficients[,4]<0.05,1])/s


```

### Study 3 (Study 2 in the new numbering)

```{r message=F, warning=F}


# Assuming the PCALoad is a good indicator, what can we say about the load of the situation?
lm3 <- lm(PCALoad1 ~ Activity + Social + Focus, data=behdata3)
summary(lm3)
anova(lm3)
# Significant trends in the linear model
s <- sd(behdata3$PCALoad1)
# Effect sizes of the significant coefficients
(summary(lm3)$coefficients[summary(lm3)$coefficients[,4]<0.05,1])/s


# Some trends/differences among technologies
lm3usu <-lm(PCALoad1 ~ Activity + Social + Focus, data=behdata3[behdata3$GroundTruth==0,])
summary(lm3usu)
anova(lm3usu)
# Effect sizes of the significant coefficients
(summary(lm3usu)$coefficients[summary(lm3usu)$coefficients[,4]<0.05,1])/s


lm3nov <-lm(PCALoad1 ~ Activity + Social + Focus, data=behdata3[behdata3$GroundTruth==1,])
summary(lm3nov)
anova(lm3nov)
# Effect sizes of the significant coefficients
(summary(lm3nov)$coefficients[summary(lm3nov)$coefficients[,4]<0.05,1])/s

```



### Study 4 (Study 3 in the new numbering)

```{r message=F, warning=F}

# We take the whole behavioral data, not only the comparable parts
bdata4 <- loaddata[!is.na(loaddata$Activity) & !is.na(loaddata$Social) & !is.na(loaddata$Focus) & loaddata$Study==4,]
# ... and we remove the samples with categorical variables that appear only very seldom
bdata4 <- bdata4[bdata4$Activity!="OFF",]
bdata4$Activity <- factor(bdata4$Activity)
bdata4 <- bdata4[bdata4$Social!="IND",]
bdata4$Social <- factor(bdata4$Social)
bdata4 <- bdata4[bdata4$Focus!="TD",]
bdata4$Focus <- factor(bdata4$Focus)

bdata4 <- within(bdata4, Focus <- relevel(Focus, ref = 2))

# Assuming the PCALoad is a good indicator, what can we say about the load of the situation?
# With all the coded episodes
lm4 <- lm(PCALoad1 ~ Activity + Social + Focus, data=bdata4)
summary(lm4)
anova(lm4)
# Significant trends in the linear model
s <- sd(bdata4$PCALoad1)
# Effect sizes of the significant coefficients
(summary(lm4)$coefficients[summary(lm4)$coefficients[,4]<0.05,1])/s

```

### Study 1 (Study 4 in the new numbering)

```{r message=F, warning=F}
# We change the reference so that it is always student faces
behdata1 <- within(behdata1, Focus <- relevel(Focus, ref = 2))

# Assuming the PCALoad is a good indicator, what can we say about the load of the situation?
lm1 <- lm(PCALoad1 ~ Activity + Social + Focus, data=behdata1)
summary(lm1)
anova(lm1)
# Significant trends in the linear model
s <- sd(behdata1$PCALoad1)
# Effect sizes of the significant coefficients
(summary(lm1)$coefficients[summary(lm1)$coefficients[,4]<0.05,1])/s

```

### Summary table


| Case study | 1 | 1 | 2 | 2 | 3 | 4 |
|:----:|:----:|:----:|:----:|:----:|:----:|:----:|
| Teacher | A | B | C | C | D | D |
| Teacher expertise | Expert | Novice | Expert | Expert | Novice | Novice |
| Tech setup | Laptops+Projector | Laptops+Projector | Laptops+Projector | Tabletops+Projector | Tabletops | Tabletops+Projector |
| Student age | Young adults | Young adults | 11-12yrs | 11-12yrs | 10-12yrs | 10-12yrs |
| No. sessions | 2 | 1 | 2 | 2 | 4 | 3 |
| No. episodes to model | 142 | 49 | 236 | 166 | 667 | 332 |
| (Intercept) | -0.64 | +1.55 | +0.39 | +1.45 | +0.95 | |
| Activity: Monitoring | | | | -1.08 | | |
| Activity: Repairs | | | | -1.07 |-0.38 | |
| Activity: Task distribution | | | | -0.75 | | |
| Social: Individual | | | -0.77 | | | |
| Social: Small group | | | | | -0.70 | |
| Focus: Student backs | | | | | -0.51 | -0.68 |
| Focus: Papers | | | -0.51 | -0.98 | | |
| Focus: Projector | | | | -1.13 | -0.49 | |
| Focus: Tabletop | | | | | -0.92 | -1.80 |
| Focus: Teacher computer | | | -0.88 | | -0.40 | |

