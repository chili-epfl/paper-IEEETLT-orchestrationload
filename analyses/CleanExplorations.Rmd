---
title: "Towards a New PCA/FA Method"
output:
  html_document: default
  pdf_document:
    keep_tex: yes
---

# Load clean/preprocessed data

The script assumes that you will put the clean datafiles (sold separately) in ```./data/study1```, ```./data/study2```, etc

```{r, message=FALSE, warning=FALSE, echo=FALSE}
source("./lib/outliers.R")
# In order to enable comparison across different sessions (even for the same subject, things like tiredness can vary the eye gaze patterns of a subject), we normalize the metrics by the average of the first three 10-second windows of the session (in which we assume similar, small load). Other possibilities for normalization: median value, scale/norm, coefficient of variance
source("./lib/loadIndex.R")

# Data for study 1
data1 <- get(load("./data/study1/study1ProcessedData.Rda"))
data1$Study <- 1

# Data for study 2
data2 <- get(load("./data/study2/study2ProcessedData.Rda"))
data2$Study <- 2
levels(data2$Focus)[levels(data2$Focus)=="TAB"] <- "DSK"
levels(data2$Focus)[levels(data2$Focus)=="WHIT"] <- "WHI"
levels(data2$Activity)[levels(data2$Activity)=="QUEST"] <- "QUE"

# Data for study 3
data3 <- get(load("./data/study3/study3ProcessedData.Rda"))
data3$Study <- 3
levels(data3$Focus)[levels(data3$Focus)=="LAP"] <- "SCOMP"
levels(data3$Focus)[levels(data3$Focus)=="PRJ"] <- "PROJ"

# Data for study 4
data4 <- get(load("./data/study4/study4ProcessedData.Rda"))
data4$Study <- 4

# Cleanup of study 4 data
names(data4)[7:10] <- c("Experimental","Social","Activity","Focus")
# from the preprocessing, the categorical values have too many levels, we fix it
data4$Experimental <- factor(data4$Experimental)
data4$Social <- factor(data4$Social)
data4$Activity <- factor(data4$Activity)
data4$Focus <- factor(data4$Focus)
data4$GroundTruth <- ifelse(data4$Experimental=="C2",1,ifelse(data4$Experimental=="C1",0,NA))
data4 <- data4[,-7] # Remove Experimental, now substituted by GroundTruth
data4 <- data4[!is.na(data4$value.Sac),] # remove samples where it was NA
#countOutliers(data4$value.Sac,coef = 5, method="iqr") # 5xinter-quartile range seems like a reasonable boundary for outliers
data4$value.Sac <- replaceOutliers(data4$value.Sac,valueNA = F,coef = 10, method="iqr") # We crop outliers beyond 10xinter-quartile range, giving them the value 5xIQR
data4$Social <- as.character(data4$Social)
data4$Activity <- as.character(data4$Activity)
data4$Focus <- as.character(data4$Focus)
data4$Subject <- "L"

# Cleanup of study 3 data
data3 <- data3[,-c(7:10,14:18)]
# Reorder the columns as in data4
data3 <- data3[,c(1:6,9,8,7,10)]
data3$GroundTruth <- ifelse(data3$session=="ISL2015NOVEL-Session3-eyetracking" | data3$session=="ISL2015NOVEL-Session4-eyetracking",1,ifelse(data3$session=="ISL2014BASELINE-Session1-eyetracking" | data3$session=="ISL2014BASELINE-Session2-eyetracking",0,NA))
data3 <- data3[!is.na(data3$value.Sac),] # remove samples where it was NA
#countOutliers(data3$value.Sac,coef = 5, method="iqr") # 5xinter-quartile range seems like a reasonable boundary for outliers
data3$value.Sac <- replaceOutliers(data3$value.Sac,valueNA = F,coef = 10, method="iqr") # We crop outliers beyond 10xinter-quartile range, giving them the value 5xIQR
data3$Social <- as.character(data3$Social)
data3$Activity <- as.character(data3$Activity)
data3$Focus <- as.character(data3$Focus)
data3$Subject <- "W"


# Cleanup of study 2 data
data2 <- data2[,-c(7:10)]
# Reorder the columns as in data4
data2 <- data2[,c(1:6,9,8,7,10)]
data2$GroundTruth <- ifelse(data2$session=="DELANA-Session3-Novice-eyetracking",1,ifelse(data2$session=="DELANA-Session1-Expert-eyetracking" | data2$session=="DELANA-Session2-Expert-eyetracking",0,NA))
data2 <- data2[!is.na(data2$value.Sac),] # remove samples where it was NA
#countOutliers(data2$value.Sac,coef = 10, method="iqr") # 5xinter-quartile range seems like a reasonable boundary for outliers
data2$value.Sac <- replaceOutliers(data2$value.Sac,valueNA = F,coef = 10, method="iqr") # We crop outliers beyond 10xinter-quartile range, giving them the value 5xIQR
data2$Social <- as.character(data2$Social)
data2$Activity <- as.character(data2$Activity)
data2$Focus <- as.character(data2$Focus)
# Solve inconsistency with other studies labels
data2[data2$GroundTruth==1,"Subject"] <- "K"
data2[data2$GroundTruth==0,"Subject"] <- "P"

# Cleanup of study 1 data
data1 <- data1[,-c(7:9)]
# Reorder the columns as in data4
data1 <- data1[,c(1:6,8,7,9,10)]
data1$GroundTruth <- NA
data1 <- data1[!is.na(data1$value.Sac),] # remove samples where it was NA
#countOutliers(data1$value.Sac,coef = 10, method="iqr") # 5xinter-quartile range seems like a reasonable boundary for outliers
data1$value.Sac <- replaceOutliers(data1$value.Sac,valueNA = F,coef = 10, method="iqr") # We crop outliers beyond 10xinter-quartile range, giving them the value 5xIQR
levels(data1$Social) <- c("CLS","GRP")
data1$Social <- as.character(data1$Social)
data1$Activity <- as.character(data1$Activity)
data1$Focus <- as.character(data1$Focus)
data1$Subject <- "L"

# Join all studies' data
totaldata <- rbind(data1,data2,data3,data4)

# Calculate different normalizations of the eyetracking metrics, and the basic load indices
loaddata <- calculateLoadIndexAndNormalizations(totaldata,3:6,stablenorm = 3)

write.csv(loaddata,file="./data/loaddata-clean.csv")

```


## Using 1st PCA component

### Global data

```{r, message=FALSE, warning=FALSE}
# We calculate the PCA load index (score in the 1st PCA component)
library(FactoMineR)
pca.global = PCA(loaddata[, 3:6], scale.unit=TRUE, ncp=2, graph=F)
plot.PCA(pca.global, axes=c(1, 2), choix="var", title="PCA All studies")
# We add the PCA load index to our dataset
loaddata$PCALoad1 = pca.global$ind$coord[,1]
loaddata$PCALoad2 = pca.global$ind$coord[,2]

# Alternative PCA method, nullifying the negative component --- Does not provide consistent and significant improvements
# v = pca.global$svd$V[,1] # The third component is negative
# v[3] = 0
# loaddata$PCALoadPos = as.matrix(t(t(loaddata[, 3:6]) - colMeans(loaddata[, 3:6]))) %*% as.matrix ( v )

# clean up further the dataset, to keep only those samples for which we have process variables
behdata <- loaddata[!is.na(loaddata$Activity) & !is.na(loaddata$Social) & !is.na(loaddata$Focus) & !is.na(loaddata$GroundTruth),]

behdata$Activity <- factor(behdata$Activity)
behdata$Social <- factor(behdata$Social)
behdata$Focus <- factor(behdata$Focus)

# We relevel the factors so that the intercept is a combination that exists in all case studies: MON/CLS/FAC
behdata <- within(behdata, Activity <- relevel(Activity, ref = 3))
behdata <- within(behdata, Focus <- relevel(Focus, ref = 3))


# See the order of factor levels
table(behdata$Activity)
table(behdata$Social)
table(behdata$Focus)

# We train an overall logistic regression model
lr1 <- glm(GroundTruth ~ Activity + Social + Focus + PCALoad1, family=binomial(link='logit'), data=behdata)
summary(lr1)
anova(lr1, test="Chisq") # PCA Load is a very significant predictor
1 - (lr1$deviance / lr1$null.deviance) # Pseudo-rsquared

# Test that alternative PCA is good enough to capture the variance
# lr1pos <- glm(GroundTruth ~ Activity + Social + Focus + PCALoadPos, family=binomial(link='logit'), data=behdata)
# summary(lr1pos)
# anova(lr1pos, test="Chisq") # PCA Load is a very significant predictor
# 1 - (lr1pos$deviance / lr1pos$null.deviance) # Pseudo-rsquared


# Validation that PCAs are good enough to capture the variance -- explained deviance is similar to this fully-optimized case
lr1b <- glm(GroundTruth ~ Activity + Social + Focus + value.Mean + value.SD + value.Sac + value.Fix, family=binomial(link='logit'), data=behdata)
summary(lr1b)
anova(lr1b, test="Chisq") # PCA Load is a very significant predictor
1 - (lr1b$deviance / lr1b$null.deviance) # Pseudo-rsquared

```

### Study 2 (Study 1 in the new order)
```{r, message=FALSE, warning=FALSE}

# We train and evaluate for each study separately
# Study 2
behdata2 <- behdata[behdata$Study==2,]
# ... and we remove the samples with categorical variables that appear only very seldom
behdata2$Activity <- factor(behdata2$Activity)
behdata2 <- behdata2[behdata2$Social!="GRP",]
behdata2$Social <- factor(behdata2$Social)
behdata2 <- behdata2[behdata2$Focus!="TEA",]
behdata2 <- behdata2[behdata2$Focus!="BAK",]
behdata2$Focus <- factor(behdata2$Focus)

# See the order of factor levels
table(behdata2$Activity)
table(behdata2$Social)
table(behdata2$Focus)


lr2 <- glm(GroundTruth ~ Activity + Social + Focus + PCALoad1, family=binomial(link='logit'), data=behdata2) # The PCA load coefficient goes in the wrong direction!!!!???
summary(lr2)
anova(lr2, test="Chisq") # PCA Load is a very significant predictor
1 - (lr2$deviance / lr2$null.deviance) # Pseudo-rsquared

```

```{r, results="asis"}

library(xtable)
xtable(summary(lr2)$coefficients, digits = c(0,2,2,2,3))

```

### Study 3 (Study 2 in the new order)

```{r, message=FALSE, warning=FALSE}

# Study 3
behdata3 <- behdata[behdata$Study==3,]
# ... and we remove the samples with categorical variables that appear only very seldom
behdata3 <- behdata3[behdata3$Activity!="DISC",]
behdata3$Activity <- factor(behdata3$Activity)
behdata3$Social <- factor(behdata3$Social)
behdata3 <- behdata3[behdata3$Focus!="TNG",]
behdata3 <- behdata3[behdata3$Focus!="RES",]
behdata3 <- behdata3[behdata3$Focus!="BAK",]
behdata3$Focus <- factor(behdata3$Focus)

# See the order of factor levels
table(behdata3$Activity)
table(behdata3$Social)
table(behdata3$Focus)

lr3 <- glm(GroundTruth ~ Activity + Social + Focus + PCALoad1, family=binomial(link='logit'), data=behdata3) # The PCA load coefficient goes in the wrong direction!!!!???
summary(lr3)
anova(lr3, test="Chisq") # PCA Load is a very significant predictor
1 - (lr3$deviance / lr3$null.deviance) # Pseudo-rsquared


```

```{r, results="asis"}

xtable(summary(lr3)$coefficients, digits = c(0,2,2,2,3))

```


### Study 4 (Study 3 in the new order)

```{r, message=FALSE, warning=FALSE}

# Study 4
# Considering extreme load episodes only -- only 163 samples after cleaning!
behdata4b <- behdata[behdata$Study==4 & behdata$CoarseLoad %in% c(0,4),]
behdata4b <- behdata4b[behdata4b$Activity!="OFF",]
behdata4b$Activity <- factor(behdata4b$Activity)
behdata4b <- behdata4b[behdata4b$Social!="IND",]
behdata4b$Social <- factor(behdata4b$Social)
behdata4b <- behdata4b[behdata4b$Focus!="TCOMP",]
behdata4b <- behdata4b[behdata4b$Focus!="TD",]
behdata4b <- behdata4b[behdata4b$Focus!="TEA",]
behdata4b <- behdata4b[behdata4b$Focus!="TPAP",]
behdata4b$Focus <- factor(behdata4b$Focus)

# See the order of factor levels
table(behdata4b$Activity)
table(behdata4b$Social)
table(behdata4b$Focus)


lr4b <- glm(GroundTruth ~ Activity + Social + Focus + PCALoad1, family=binomial(link='logit'), data=behdata4b) # The PCA load coefficient goes in the right direction, but is not significant
summary(lr4b)
anova(lr4b, test="Chisq") # PCA Load is a very significant predictor
1 - (lr4b$deviance / lr4b$null.deviance) # Pseudo-rsquared=0.05


```

```{r, results="asis"}

xtable(summary(lr4b)$coefficients, digits = c(0,2,2,2,3))

```

### Study 1 (Study 4 in the new order)
```{r, message=FALSE, warning=FALSE}
# We train and evaluate for each study separately
# Study 2
behdata1 <- loaddata[!is.na(loaddata$Activity) & !is.na(loaddata$Social) & !is.na(loaddata$Focus) & loaddata$Study==1,]
# ... and we remove the samples with categorical variables that appear only very seldom
behdata1$Activity <- factor(behdata1$Activity)
behdata1$Social <- factor(behdata1$Social)
behdata1 <- behdata1[behdata1$Focus!="W",]
behdata1 <- behdata1[behdata1$Focus!="M",]
behdata1 <- behdata1[behdata1$Focus!="RES",]
behdata1$Focus <- factor(behdata1$Focus)

behdata1 <- within(behdata1, Activity <- relevel(Activity, ref = 2))
behdata1 <- within(behdata1, Focus <- relevel(Focus, ref = 2))

# See the order of factor levels
table(behdata1$Activity)
table(behdata1$Social)
table(behdata1$Focus)


# Assuming the PCALoad is a good indicator, what can we say about the load of the situation?
behdata1$session <- factor(behdata1$session)
lm1sess <- lm(PCALoad1 ~ Activity + Social + Focus + session, data=behdata1)
summary(lm1sess)
anova(lm1sess)

```


```{r, results="asis"}

xtable(summary(lm1sess)$coefficients, digits = c(0,2,2,2,3))

```

## Big table of linear models and significant effect sizes


### Study 2 (Study 1 in the new numbering)

```{r message=F, warning=F}


# Assuming the PCALoad is a good indicator, what can we say about the load of the situation?
lm2 <- lm(PCALoad1 ~ Activity + Social + Focus, data=behdata2)
summary(lm2)
anova(lm2)
# Significant trends in the linear model
s <- sd(behdata2$PCALoad1)
# Effect sizes of the significant coefficients
sizes <- (summary(lm2)$coefficients[summary(lm2)$coefficients[,4]<0.05,1])/s

# Some trends/differences among teachers (not quite significant, tho)
lm2exp <-lm(PCALoad1 ~ Activity + Social + Focus, data=behdata2[behdata2$GroundTruth==0,])
summary(lm2exp)
anova(lm2exp)
# Effect sizes of the significant coefficients
sizes <- (summary(lm2exp)$coefficients[summary(lm2exp)$coefficients[,4]<0.05,1])/s

results2exp <- data.frame(Case="1",Teacher="A",Expertise="Expert",Technology="Laptops+Projector",Students="Young adults", stringsAsFactors = F)
results2exp$No.sessions <- length(unique(behdata2[behdata2$GroundTruth==0,"session"]))
results2exp$No.episodes <- sum(table(behdata2[behdata2$GroundTruth==0,"Activity"]))
results2exp$Rsquared.adj <- summary(lm2exp)$adj.r.squared
if(length(names(sizes))==0){
  results2exp$Intercept <- sizes
} else {
  results2exp <- cbind(results2exp,as.data.frame(t(sizes)))
  if(names(results2exp)[9]=="(Intercept)") names(results2exp)[9] <- "Intercept" 
} 



lm2nov <-lm(PCALoad1 ~ Activity + Social + Focus, data=behdata2[behdata2$GroundTruth==1,])
summary(lm2nov)
anova(lm2nov)
# Effect sizes of the significant coefficients
sizes <- (summary(lm2nov)$coefficients[summary(lm2nov)$coefficients[,4]<0.05,1])/s

results2nov <- data.frame(Case="1",Teacher="B",Expertise="Novice",Technology="Laptops+Projector",Students="Young adults", stringsAsFactors = F)
results2nov$No.sessions <- length(unique(behdata2[behdata2$GroundTruth==1,"session"]))
results2nov$No.episodes <- sum(table(behdata2[behdata2$GroundTruth==1,"Activity"]))
results2nov$Rsquared.adj <- summary(lm2nov)$adj.r.squared
if(length(names(sizes))==0){
  results2nov$Intercept <- sizes
} else {
  results2nov <- cbind(results2nov,as.data.frame(t(sizes)))
  if(names(results2nov)[9]=="(Intercept)") names(results2nov)[9] <- "Intercept" 
} 
```


### Study 3 (Study 2 in the new numbering)

```{r message=F, warning=F}


# Assuming the PCALoad is a good indicator, what can we say about the load of the situation?
lm3 <- lm(PCALoad1 ~ Activity + Social + Focus, data=behdata3)
summary(lm3)
anova(lm3)
# Significant trends in the linear model
s <- sd(behdata3$PCALoad1)
# Effect sizes of the significant coefficients
sizes <- (summary(lm3)$coefficients[summary(lm3)$coefficients[,4]<0.05,1])/s


# Some trends/differences among technologies
lm3usu <-lm(PCALoad1 ~ Activity + Social + Focus, data=behdata3[behdata3$GroundTruth==0,])
summary(lm3usu)
anova(lm3usu)
# Effect sizes of the significant coefficients
sizes <- (summary(lm3usu)$coefficients[summary(lm3usu)$coefficients[,4]<0.05,1])/s

results3usu <- data.frame(Case="2",Teacher="C",Expertise="Expert",Technology="Laptops+Projector",Students="11-12yrs", stringsAsFactors = F)
results3usu$No.sessions <- length(unique(behdata3[behdata3$GroundTruth==0,"session"]))
results3usu$No.episodes <- sum(table(behdata3[behdata3$GroundTruth==0,"Activity"]))
results3usu$Rsquared.adj <- summary(lm3usu)$adj.r.squared
if(length(names(sizes))==0){
  results3usu$Intercept <- sizes
} else {
  results3usu <- cbind(results3usu,as.data.frame(t(sizes)))
  if(names(results3usu)[9]=="(Intercept)") names(results3usu)[9] <- "Intercept" 
} 


lm3nov <-lm(PCALoad1 ~ Activity + Social + Focus, data=behdata3[behdata3$GroundTruth==1,])
summary(lm3nov)
anova(lm3nov)
# Effect sizes of the significant coefficients
sizes <- (summary(lm3nov)$coefficients[summary(lm3nov)$coefficients[,4]<0.05,1])/s
results3nov <- data.frame(Case="2",Teacher="C",Expertise="Expert",Technology="Tabletops+Projector",Students="11-12yrs", stringsAsFactors = F)
results3nov$No.sessions <- length(unique(behdata3[behdata3$GroundTruth==1,"session"]))
results3nov$No.episodes <- sum(table(behdata3[behdata3$GroundTruth==1,"Activity"]))
results3nov$Rsquared.adj <- summary(lm3nov)$adj.r.squared
if(length(names(sizes))==0){
  results3nov$Intercept <- sizes
} else {
  results3nov <- cbind(results3nov,as.data.frame(t(sizes)))
  if(names(results3nov)[9]=="(Intercept)") names(results3nov)[9] <- "Intercept" 
} 
```



### Study 4 (Study 3 in the new numbering)

```{r message=F, warning=F}

# We take the whole behavioral data, not only the comparable parts
bdata4 <- loaddata[!is.na(loaddata$Activity) & !is.na(loaddata$Social) & !is.na(loaddata$Focus) & loaddata$Study==4,]
# ... and we remove the samples with categorical variables that appear only very seldom
bdata4 <- bdata4[bdata4$Activity!="OFF",]
bdata4$Activity <- factor(bdata4$Activity)
bdata4 <- bdata4[bdata4$Social!="IND",]
bdata4$Social <- factor(bdata4$Social)
bdata4 <- bdata4[bdata4$Focus!="TD",]
bdata4$Focus <- factor(bdata4$Focus)

bdata4 <- within(bdata4, Activity <- relevel(Activity, ref = 2))
bdata4 <- within(bdata4, Focus <- relevel(Focus, ref = 2))

# Assuming the PCALoad is a good indicator, what can we say about the load of the situation?
# With all the coded episodes
lm4 <- lm(PCALoad1 ~ Activity + Social + Focus, data=bdata4)
summary(lm4)
anova(lm4)
# Significant trends in the linear model
s <- sd(bdata4$PCALoad1)
# Effect sizes of the significant coefficients
sizes <- (summary(lm4)$coefficients[summary(lm4)$coefficients[,4]<0.05,1])/s
results4 <- data.frame(Case="3",Teacher="D",Expertise="Novice",Technology="Tabletops+Projector",Students="10-12yrs", stringsAsFactors = F)
results4$No.sessions <- length(unique(bdata4[,"session"]))
results4$No.episodes <- sum(table(bdata4[,"Activity"]))
results4$Rsquared.adj <- summary(lm4)$adj.r.squared
if(length(names(sizes))==0){
  results4$Intercept <- sizes
} else {
  results4 <- cbind(results4,as.data.frame(t(sizes)))
  if(names(results4)[9]=="(Intercept)") names(results4)[9] <- "Intercept" 
} 

```



### Study 1 (Study 4 in the new numbering)

```{r message=F, warning=F}
# We change the reference so that it is always student faces

# Assuming the PCALoad is a good indicator, what can we say about the load of the situation?
lm1 <- lm(PCALoad1 ~ Activity + Social + Focus, data=behdata1)
summary(lm1)
anova(lm1)
# Significant trends in the linear model
s <- sd(behdata1$PCALoad1)
# Effect sizes of the significant coefficients
sizes <- (summary(lm1)$coefficients[summary(lm1)$coefficients[,4]<0.05,1])/s
results1 <- data.frame(Case="4",Teacher="D",Expertise="Novice",Technology="Tabletops only",Students="10-12yrs", stringsAsFactors = F)
results1$No.sessions <- length(unique(behdata1[,"session"]))
results1$No.episodes <- sum(table(behdata1[,"Activity"]))
results1$Rsquared.adj <- summary(lm1)$adj.r.squared
if(length(names(sizes))==0){
  results1$Intercept <- sizes
} else {
  results1 <- cbind(results1,as.data.frame(t(sizes)))
  if(names(results1)[9]=="(Intercept)") names(results1)[9] <- "Intercept" 
} 

```






### Laptops vs. Tabletops

```{r message=F, warning=F}
################################################################
# Laptops: data2+data3usu
behdata3lap <- behdata3[behdata3$GroundTruth==0,]

behdatalap <- rbind(behdata2,behdata3lap)
behdatalap$Activity <- factor(behdatalap$Activity)
behdatalap$Social <- factor(behdatalap$Social)
behdatalap$Focus <- factor(behdatalap$Focus)

table(behdatalap$Activity)
table(behdatalap$Social)
table(behdatalap$Focus)
# Relevel?

# Assuming the PCALoad is a good indicator, what can we say about the load of the situation?
lmlap <- lm(PCALoad1 ~ Activity + Social + Focus, data=behdatalap)
summary(lmlap)
anova(lmlap)
# Significant trends in the linear model
s <- sd(behdatalap$PCALoad1)
# Effect sizes of the significant coefficients
sizes <- (summary(lmlap)$coefficients[summary(lmlap)$coefficients[,4]<0.05,1])/s
resultslap <- data.frame(Case="1+2",Teacher="A+B+C",Expertise="Varied",Technology="Laptops+Projector",Students="Varied", stringsAsFactors = F)
resultslap$No.sessions <- length(unique(behdatalap[,"session"]))
resultslap$No.episodes <- sum(table(behdatalap[,"Activity"]))
resultslap$Rsquared.adj <- summary(lmlap)$adj.r.squared
if(length(names(sizes))==0){
  resultslap$Intercept <- sizes
} else {
  resultslap <- cbind(resultslap,as.data.frame(t(sizes)))
  if(names(resultslap)[9]=="(Intercept)") names(resultslap)[9] <- "Intercept" 
} 


################################################################
# Tabletops: data1+data3nov+data4
behdata3tab <- behdata3[behdata3$GroundTruth==1,]

behdatatab <- rbind(behdata1,behdata3tab,bdata4)
behdatatab$Activity <- factor(behdatatab$Activity)
behdatatab$Social <- factor(behdatatab$Social)
behdatatab$Focus <- factor(behdatatab$Focus)

table(behdatatab$Activity)
table(behdatatab$Social)
table(behdatatab$Focus)

# Assuming the PCALoad is a good indicator, what can we say about the load of the situation?
lmtab <- lm(PCALoad1 ~ Activity + Social + Focus, data=behdatatab)
summary(lmtab)
anova(lmtab)
# Significant trends in the linear model
s <- sd(behdatatab$PCALoad1)
# Effect sizes of the significant coefficients
sizes <- (summary(lmtab)$coefficients[summary(lmtab)$coefficients[,4]<0.05,1])/s
resultstab <- data.frame(Case="2+3+4",Teacher="C+D",Expertise="Varied",Technology="Tabletops",Students="10-12yrs", stringsAsFactors = F)
resultstab$No.sessions <- length(unique(behdatatab[,"session"]))
resultstab$No.episodes <- sum(table(behdatatab[,"Activity"]))
resultstab$Rsquared.adj <- summary(lmtab)$adj.r.squared
if(length(names(sizes))==0){
  resultstab$Intercept <- sizes
} else {
  resultstab <- cbind(resultstab,as.data.frame(t(sizes)))
  if(names(resultstab)[9]=="(Intercept)") names(resultstab)[9] <- "Intercept" 
} 

```





### Overall dataset!?

```{r message=F, warning=F}

behdataall <- rbind(behdata1,behdata2,behdata3,bdata4)
behdataall$Activity <- factor(behdataall$Activity)
behdataall$Social <- factor(behdataall$Social)
behdataall$Focus <- factor(behdataall$Focus)

table(behdataall$Activity)
table(behdataall$Social)
table(behdataall$Focus)

# Assuming the PCALoad is a good indicator, what can we say about the load of the situation?
lmall <- lm(PCALoad1 ~ Activity + Social + Focus, data=behdataall)
summary(lmall)
anova(lmall)
# Significant trends in the linear model
s <- sd(behdataall$PCALoad1)
# Effect sizes of the significant coefficients
sizes <- (summary(lmall)$coefficients[summary(lmall)$coefficients[,4]<0.05,1])/s
resultsall <- data.frame(Case="1+2+3+4",Teacher="A+B+C+D",Expertise="Varied",Technology="Varied",Students="Varied", stringsAsFactors = F)
resultsall$No.sessions <- length(unique(behdataall[,"session"]))
resultsall$No.episodes <- sum(table(behdataall[,"Activity"]))
resultsall$Rsquared.adj <- summary(lmall)$adj.r.squared
if(length(names(sizes))==0){
  resultsall$Intercept <- sizes
} else {
  resultsall <- cbind(resultsall,as.data.frame(t(sizes)))
  if(names(resultsall)[9]=="(Intercept)") names(resultsall)[9] <- "Intercept" 
} 

```


### Summary table


```{r, results="asis"}


results <- merge(rbind(results2exp,results2nov),results3usu,all = T)
results <- merge(results,results3nov,all=T)
results <- merge(results,results4, all=T)
results <- merge(results,results1, all=T)
results <- merge(results,resultslap, all=T)
results <- merge(results,resultstab, all=T)
results <- merge(results, resultsall, all=T)
#Reorder the rows to get the desired table layout
results <- results[c(1:2,5:6,8:9,3,7,4),]
library(xtable)
#tr <- xtable(results,digits=2)
#print(xtable(t( mapply("format", results, digits=c(0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2)))), type="html")
print(xtable(t( mapply("format", results, digits=c(0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2)))))

```
