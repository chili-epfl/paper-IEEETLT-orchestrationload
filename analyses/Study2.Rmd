---
title: "Study2"
author: "lprisan"
date: "20 de marzo de 2016"
output: html_document
---

(add some contextual info from the paper)

As a first step, we download the [dataset for Study 2](https://zenodo.org/record/16514), (which has been published in Zenodo), and preprocess it. The preprocessing again consists on aggregating the four load-related eyetracking metrics into 10-second episodes, using a rolling window with 5-second slide between windows. Then, that aggregated data is merged with the video codes generated by researchers, regarding the social level, teacher activity and gaze focus (during the 10-second episodes where all eyetracking metrics agreed on high/low values). 

```{r, message=FALSE, warning=FALSE, echo=FALSE}
library(ggplot2)
# We load the useful scripts and packages needed throughout the report
source("./lib/rollingWindows.R")
source("./lib/loadIndex.R")
source("./lib/extremeLoadExtraction.R")
source("./lib/aggregateEpisodeData.R")
source("./lib/multiplot.R")
source("./lib/outliers.R")
source("./lib/predictor.R")

# Create the directory structure onto which download the data
rootdir <- getwd()
datadir <- paste(rootdir,"data","study2",sep=.Platform$file.sep)
if(!dir.exists(datadir)) dir.create(datadir, recursive=T)
setwd(datadir)

# We download the data
if(!file.exists("DELANA-VideoCodingData.zip") || !file.exists("DELANA-EyetrackingData.zip")){
    download.file("https://zenodo.org/record/16514/files/DELANA-VideoCodingData.zip", destfile="DELANA-VideoCodingData.zip", method="curl")
    unzip("DELANA-VideoCodingData.zip")
    download.file("https://zenodo.org/record/16514/files/DELANA-EyetrackingData.zip", destfile="DELANA-EyetrackingData.zip", method="curl")
    unzip("DELANA-EyetrackingData.zip")
} 

# Now we have the raw data files uncompressed in the data/study2 folder

sessions <-  c("DELANA-Session1-Expert-eyetracking","DELANA-Session2-Expert-eyetracking","DELANA-Session3-Novice-eyetracking")

totaldata <- data.frame()
cleandatafile <- "study2ProcessedData.Rda"
if(!file.exists(cleandatafile)){
    data <- aggregateEpisodeData(sessions, datadir=datadir, initendtimes=NULL, SEPARATOR=";") # For this study the raw data is semicolon-separated, for the fix/sac at least!
    data <- data[,c(1:5,12)] # We select only the load-related metrics
    # We load and add the video coding data with the social, activity and main gaze focus dimensions
    videocodes <- read.csv("DELANA-videocoding.csv", sep=",")
    videocodes$session <- videocodes$Session
    totaldata <- merge(data,videocodes,by=c("session","time"),all=T)
    save(totaldata, file=cleandatafile)
}else{
  totaldata <- get(load(file=cleandatafile))
}


# We crop outliers in the saccade speed. They tend to throw off the HMM and PCA calculations
#countOutliers(totaldata$value.Sac,coef = 5, method="iqr") # 5xinter-quartile range
totaldata$value.Sac <- replaceOutliers(totaldata$value.Sac,valueNA = F,coef = 5, method="iqr")

loaddata <- calculateCoarseFineLoadIndex(totaldata,3:6,normalize=T,stablenorm = 3) # We ensure that the values are normalized for those of the first window in which little load is assumed (just putting the eyetracker on)
#str(loaddata)
#names(loaddata)


# We assume that the teacher load in the expert sessions (1,2) is lower than in the novice sessions (session 3)
loaddata$TeacherLoad <- ifelse(loaddata$session==sessions[3],1,0)
# table(loaddata$TeacherLoad,loaddata$Activity)
# table(loaddata$TeacherLoad,loaddata$Social)
# table(loaddata$TeacherLoad,loaddata$Focus)
dataexpert <- loaddata[loaddata$TeacherLoad==0,]
datanovice <- loaddata[loaddata$TeacherLoad==1,]

```

Aside from those variables in Study 1, we have another "assumed ground truth" variable (`TeacherLoad`), which associates the **Expert teacher** sessions with *lower* loads and the **Novice teacher** sessions with *higher* loads.

## Calcualte the PCA Load Index (both teachers)

```{r, message=FALSE, warning=FALSE, echo=FALSE}

# We calculate the PCA load index (separately for the expert and novice teacher)
library(FactoMineR)

res.pca.norm = PCA(loaddata[, c(14,17,20,23)], scale.unit=TRUE, ncp=5, graph=F)
plot.PCA(res.pca.norm, axes=c(1, 2), choix="var", title="PCA BOTH expert/novice, Normalized data, dims 1/2")
loaddata$PCALoad1 = res.pca.norm$ind$coord[,1]
loaddata$PCALoad2 = res.pca.norm$ind$coord[,2]


# clean up further the dataset, to keep only those samples for which we have process variables
behdata <- loaddata[!is.na(loaddata$Activity) & !is.na(loaddata$Social) & !is.na(loaddata$Focus),]
# We take only the samples for which we have a meaningful ground truth
behdata <- behdata[!is.na(behdata$TeacherLoad),]
# ... and we remove the samples with categorical variables that appear only very seldom
# behdata <- behdata[behdata$value.Activity!="EXP",]
# behdata <- behdata[behdata$value.Activity!="OFF",]
# behdata <- behdata[behdata$value.Activity!="TEC",]
# behdata$value.Activity <- factor(behdata$value.Activity)
# behdata <- behdata[behdata$value.Social!="IND",]
# behdata$value.Social <- factor(behdata$value.Social)
# behdata <- behdata[behdata$value.Focus!="WHI",]
# behdata <- behdata[behdata$value.Focus!="TCOMP",]
# behdata <- behdata[behdata$value.Focus!="TD",]
# behdata <- behdata[behdata$value.Focus!="TEA",]
# behdata <- behdata[behdata$value.Focus!="TPAP",]
# behdata$value.Focus <- factor(behdata$value.Focus)

# We train the logistic regression model
lr1 <- glm(TeacherLoad ~ Activity + Social + Focus + PCALoad1 + PCALoad2, family=binomial(link='logit'), data=behdata) # The PCA load coefficient goes in the wrong direction!!!!???
summary(lr1)
anova(lr1, test="Chisq") # PCA Load is a very significant predictor
lr2 <- glm(TeacherLoad ~ value.Activity + value.Social + value.Focus + value.Mean.norm + value.SD.norm + value.Fix.norm + value.Sac.norm, family=binomial(link='logit'), data=behdata) # The PCA load coefficient goes in the wrong direction!!!!???
summary(lr2)
anova(lr2, test="Chisq") # PCA Load is a very significant predictor




```


## Calculate the PCA Load index

... from the eyetracking metrics, normalized by the value of the first three 10-s windows, to account for variations in the day's data (e.g., due to tiredness, etc.)

```{r, message=FALSE, warning=FALSE, echo=FALSE}

# We calculate the PCA load index (separately for the expert and novice teacher)
library(FactoMineR)

res.pca.norm = PCA(dataexpert[, c(14,17,20,23)], scale.unit=TRUE, ncp=5, graph=F)
plot.PCA(res.pca.norm, axes=c(1, 2), choix="var", title="PCA Expert, Normalized data, dims 1/2")
dataexpert$PCALoad = res.pca.norm$ind$coord[,1]

res.pca.norm = PCA(datanovice[, c(14,17,20,23)], scale.unit=TRUE, ncp=5, graph=F)
plot.PCA(res.pca.norm, axes=c(1, 2), choix="var", title="PCA Novice, Normalized data, dims 1/2")
datanovice$PCALoad = res.pca.norm$ind$coord[,1]

loaddata <- rbind(dataexpert,datanovice)

# We plot the loads for each session, along with some smoothing
for(session in sessions){
    sessiondata <- loaddata[loaddata$session==session,]
    p1 <- ggplot(sessiondata, aes(x=time/60000, y=PCALoad, col=PCALoad)) + 
            ggtitle(paste("PCA Load Index ",session,sep="")) + 
            geom_line(size=1) + stat_smooth(method="loess",span=0.1,se=F) +
            #theme(axis.text.x = element_text(size=18),plot.title=element_text(size=20, face="bold"),axis.title=element_text(size=18),panel.background = element_rect(fill = 'white')) +
            theme(panel.background = element_rect(fill = 'white')) +
            scale_color_gradient(low="green",high="red")
    print(p1)

}

```


## Validation of the PCA Load measure

That is: Can this PCA Load index help us distinguish between expert teacher sessions and novice teacher sessions? Or, put another way, is the PCA Load index different, once we remove the effect of the other process variables (teacher activity, social plane of interaction, main focus of the gaze)

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}

behdata <- loaddata[!is.na(loaddata$Activity) & !is.na(loaddata$Social) & !is.na(loaddata$Focus),]

# We remove the levels for which we do not have enough data
behdata <- behdata[behdata$Social!="GRP",]
behdata$Social <- factor(behdata$Social)
behdata <- behdata[behdata$Focus!="BAK",]
behdata <- behdata[behdata$Focus!="TAB",]
behdata <- behdata[behdata$Focus!="TEA",]
behdata$Focus <- factor(behdata$Focus)
```

### Error in a linear model

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
lmbase <- lm(PCALoad ~ Activity + Social + Focus, data = behdata)
summary(lmbase)
anova(lmbase)

behdata$errorlm <- getModelError(behdata,c("Activity","Social","Focus"), lmbase, "PCALoad")
t.test(behdata[behdata$TeacherLoad==0,"errorlm"],behdata[behdata$TeacherLoad==1,"errorlm"])
ggplot(behdata, aes(x=errorlm, col=factor(TeacherLoad)))+geom_density()

```


### Logistic regression model

To do so, we train a logistic regression model that tries to predict the "teacher expertise condition" on the basis of the PCA Load index and the orchestration process variables coded by a human:

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}


# We train the logistic regression model
lr1 <- glm(TeacherLoad ~ Activity + Social + Focus + PCALoad, family=binomial(link='logit'), data=behdata)
summary(lr1)
anova(lr1, test="Chisq")
library(caret)
set.seed(1)
Train <- createDataPartition(behdata$TeacherLoad, p=0.7, list=FALSE)
training <- behdata[ Train, ]
testing <- behdata[ -Train, ]
#mod_fit <- train(TeacherLoad ~ Activity + Social + Focus + PCALoad,  
#                 data=training, method="glm", family="binomial")

mod_fit <- glm(TeacherLoad ~ Activity + Social + Focus + PCALoad, 
                   data=training, family="binomial")
mod_fit_base <- glm(TeacherLoad ~ Activity + Social + Focus, 
                   data=training, family="binomial")

# Compare the model with PCA load with the model without it
print("ANOVA of logistic regression models with and without the PCA Load as a variable")
anova(mod_fit_base, mod_fit, test ="Chisq")

# McFadden's pseudo-Rsquared, to get an idea of the proportion of variance explained
library(pscl)
print("McFadden's pseudo Rsquared, base model WITHOUT PCA Load")
pR2(mod_fit_base)["McFadden"]  # look for 'McFadden', 0.38
print("McFadden's pseudo Rsquared, model WITH PCA Load")
pR2(mod_fit)["McFadden"]  # look for 'McFadden', 0.48

# Wald test for individual predictors
library(survey)
#regTermTest(mod_fit, "Activity")
#regTermTest(mod_fit, "Social") # p=0.004, removing this variable would harm substantially the fit of the model
#regTermTest(mod_fit, "Focus")
print("Wald test: would removing the PCA Load harm the model fit")
regTermTest(mod_fit, "PCALoad") # p=0.002, removing this variable would harm substantially the fit of the model

# Variable importance
print("Variable importance")
varImp(mod_fit) # PCALoad is the most important variable

# Predictions and accuracy of the model (as a curiosity)
# ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE)
# mod_fit <- train(TeacherLoad ~ Activity + Social + Focus + PCALoad,  data=training,
#                  method="glm", family="binomial", trControl = ctrl, tuneLength = 5)
# mod_base <- train(TeacherLoad ~ Activity + Social + Focus,  data=training,
#                  method="glm", family="binomial", trControl = ctrl, tuneLength = 5)
# pred = predict(mod_fit, newdata=testing)
# predbase = predict(mod_base, newdata=testing)
# eval = data.frame(cutoff=seq(from=0, to=1, length.out=100))
# eval$base = NA
# eval$model = NA
# for(i in 1:nrow(eval)){
#     eval[i,"model"] <- confusionMatrix(data=ifelse(pred>eval$cutoff[i],1,0), testing$TeacherLoad)$overall["Accuracy"]
#     eval[i,"base"] <- confusionMatrix(data=ifelse(predbase>eval$cutoff[i],1,0), testing$TeacherLoad)$overall["Accuracy"]
# }
# ggplot(eval, aes(x=cutoff, y=model))+geom_line()+geom_line(aes(y=base), col="red")
# max(eval$model) # Max accuracy, 93%
# max(eval$base) # Max accuracy, 91%

```

We observe that not only the PCALoad is a significant predictor of the assumed ground truth variable, it is actually the most important variable in the model, even more so than the other process variables (activity, social & focus).


## Orchestration load patterns (linear model)


To get an idea of how the PCA load index is related to the different kinds of classroom episodes, in terms of the orchestration dimensions coded by a human researcher (teacher activity, social plane of interaction and main focus of the teacher gaze), we can produce a linear model for the expert teacher and another one for the novice:

**Expert teacher**

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}

# Expert teacher
behexpert <- dataexpert[!is.na(dataexpert$Activity) & !is.na(dataexpert$Social) & !is.na(dataexpert$Focus),]

#ggplot(behexpert,aes(x=PCALoad))+geom_density()
# The distribution of coded values goes continuouosly along the dimension, so we do a linear model

# Optional: delete the factor values with too few occurrences?
behexpert$Social <- factor(behexpert$Social)
behexpert <- behexpert[behexpert$Focus!="BAK",]
behexpert <- behexpert[behexpert$Focus!="SCOMP",]
behexpert <- behexpert[behexpert$Focus!="TAB",]
behexpert <- behexpert[behexpert$Focus!="TEA",]
behexpert$Focus <- factor(behexpert$Focus)

lmexp <- lm(PCALoad ~ Activity + Social + Focus, data = behexpert)
summary(lmexp)
anova(lmexp, test="Chisq")
```

We observe that, for these episodes coded, a simple linear model of the three orchestration dimensions explains only 3% of the variance in PCA Load Index, and the predictor is not significantly better than a constant/random one. In this case we see that the social level is the only variable that hints at a significant contribution to the predictor model (load of INDividual interaction episodes tend to be lower than the intercept CLSs-wide ones).

**Novice teacher**

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}

# Novice teacher
behnovice <- datanovice[!is.na(datanovice$Activity) & !is.na(datanovice$Social) & !is.na(datanovice$Focus),]

#ggplot(behnovice,aes(x=PCALoad))+geom_density()
# The distribution of coded values goes continuouosly along the dimension, so we do a linear model

# Optional: delete the factor values with too few occurrences?
behnovice <- behnovice[behnovice$Activity!="QUEST",]
behnovice <- behnovice[behnovice$Activity!="TDT",]
behnovice$Activity <- factor(behnovice$Activity)
behnovice <- behnovice[behnovice$Social!="GRP",]
behnovice$Social <- factor(behnovice$Social)
behnovice <- behnovice[behnovice$Focus!="BAK",]
behnovice <- behnovice[behnovice$Focus!="PROJ",]
behnovice <- behnovice[behnovice$Focus!="TAB",]
behnovice <- behnovice[behnovice$Focus!="TEA",]
behnovice <- behnovice[behnovice$Focus!="WHIT",]
behnovice$Focus <- factor(behnovice$Focus)

lmnov <- lm(PCALoad ~ Activity + Social + Focus, data = behnovice)
summary(lmnov)
anova(lmnov, test="Chisq")
```

We observe that, for these episodes coded, a simple linear model of the three orchestration dimensions explains 11% of the variance in PCA Load Index, and the model is not significantly better than a trivial one. Only the teaching activity seems to be predicting significantly (EXPlanations seem to be higher load in general).




## Appendix: Using Factor analysis instead of PCA load index

... results are largely the same, even if some of the coefficient estimations are different

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}

library(psych)

#Expert
Xe <- dataexpert[, c(14,17,20,23)]
Ne <- nrow(dataexpert[, c(14,17,20,23)])
corMate <- cor(Xe)
faPCe  <- fa(r=corMate, nfactors=1, n.obs=Ne, rotate="varimax")
bartlette <- factor.scores(x=Xe, f=faPCe, method="Bartlett")
dataexpert$FALoad <- bartlette$scores[,1]
# factor.plot(faPCe, cut=0.3)
# fa.diagram(faPCe)
# fa.parallel(Xe)
# vss(Xe, n.obs=Ne, rotate="varimax")

#Novice
Xn <- datanovice[, c(14,17,20,23)]
Nn <- nrow(datanovice[, c(14,17,20,23)])
corMatn <- cor(Xn)
faPCn  <- fa(r=corMatn, nfactors=1, n.obs=Nn, rotate="varimax")
bartlettn <- factor.scores(x=Xn, f=faPCn, method="Bartlett")
datanovice$FALoad <- bartlettn$scores[,1]
# factor.plot(faPCn, cut=0.3)
# fa.diagram(faPCn)
# fa.parallel(Xn)
# vss(Xn, n.obs=Nn, rotate="varimax")

loaddata <- rbind(dataexpert,datanovice)

behdata <- loaddata[!is.na(loaddata$Activity) & !is.na(loaddata$Social) & !is.na(loaddata$Focus),]

# We remove the levels for which we do not have enough data
behdata <- behdata[behdata$Social!="GRP",]
behdata$Social <- factor(behdata$Social)
behdata <- behdata[behdata$Focus!="BAK",]
behdata <- behdata[behdata$Focus!="TAB",]
behdata <- behdata[behdata$Focus!="TEA",]
behdata$Focus <- factor(behdata$Focus)

# Validation of FALoad using logistic regression model
lr1 <- glm(TeacherLoad ~ Activity + Social + Focus + FALoad, family=binomial(link='logit'), data=behdata)
summary(lr1)
anova(lr1, test="Chisq")
library(caret)
set.seed(1)
Train <- createDataPartition(behdata$TeacherLoad, p=0.7, list=FALSE)
training <- behdata[ Train, ]
testing <- behdata[ -Train, ]
#mod_fit <- train(TeacherLoad ~ Activity + Social + Focus + FALoad,  
#                 data=training, method="glm", family="binomial")
mod_fit <- glm(TeacherLoad ~ Activity + Social + Focus + FALoad, 
                   data=training, family="binomial")
mod_fit_base <- glm(TeacherLoad ~ Activity + Social + Focus, 
                   data=training, family="binomial")
# Compare the model with FA load with the model without it
print("ANOVA of logistic regression models with and without the FA Load as a variable")
anova(mod_fit_base, mod_fit, test ="Chisq")
# McFadden's pseudo-Rsquared, to get an idea of the proportion of variance explained
library(pscl)
print("McFadden's pseudo Rsquared, base model WITHOUT FA Load")
pR2(mod_fit_base)["McFadden"]  # look for 'McFadden'
print("McFadden's pseudo Rsquared, model WITH FA Load")
pR2(mod_fit)["McFadden"]  # look for 'McFadden'
# Wald test for individual predictors
library(survey)
#regTermTest(mod_fit, "Activity")
#regTermTest(mod_fit, "Social") # 
#regTermTest(mod_fit, "Focus")
print("Wald test: would removing the FA Load harm the model fit")
regTermTest(mod_fit, "FALoad") #
# Variable importance
print("Variable importance")
varImp(mod_fit) # FALoad is the most important variable


# What about the orchestration patterns?

# Expert teacher
behexpert <- dataexpert[!is.na(dataexpert$Activity) & !is.na(dataexpert$Social) & !is.na(dataexpert$Focus),]
#ggplot(behexpert,aes(x=FALoad))+geom_density()
# The distribution of coded values goes continuouosly along the dimension, so we do a linear model
# Optional: delete the factor values with too few occurrences?
behexpert$Social <- factor(behexpert$Social)
behexpert <- behexpert[behexpert$Focus!="BAK",]
behexpert <- behexpert[behexpert$Focus!="SCOMP",]
behexpert <- behexpert[behexpert$Focus!="TAB",]
behexpert <- behexpert[behexpert$Focus!="TEA",]
behexpert$Focus <- factor(behexpert$Focus)
lmexp <- lm(FALoad ~ Activity + Social + Focus, data = behexpert)
summary(lmexp)
anova(lmexp, test="Chisq")

# Novice teacher
behnovice <- datanovice[!is.na(datanovice$Activity) & !is.na(datanovice$Social) & !is.na(datanovice$Focus),]
#ggplot(behnovice,aes(x=FALoad))+geom_density()
# The distribution of coded values goes continuouosly along the dimension, so we do a linear model
# Optional: delete the factor values with too few occurrences?
behnovice <- behnovice[behnovice$Activity!="QUEST",]
behnovice <- behnovice[behnovice$Activity!="TDT",]
behnovice$Activity <- factor(behnovice$Activity)
behnovice <- behnovice[behnovice$Social!="GRP",]
behnovice$Social <- factor(behnovice$Social)
behnovice <- behnovice[behnovice$Focus!="BAK",]
behnovice <- behnovice[behnovice$Focus!="PROJ",]
behnovice <- behnovice[behnovice$Focus!="TAB",]
behnovice <- behnovice[behnovice$Focus!="TEA",]
behnovice <- behnovice[behnovice$Focus!="WHIT",]
behnovice$Focus <- factor(behnovice$Focus)
lmnov <- lm(FALoad ~ Activity + Social + Focus, data = behnovice)
summary(lmnov)
anova(lmnov, test="Chisq")

```





***



```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
# We go back to the root directory for the next study's scripts
setwd(rootdir)
```

