---
title: "Study2"
author: "lprisan"
date: "20 de marzo de 2016"
output: html_document
---

(add some contextual info from the paper)

As a first step, we download the [dataset for Study 2](https://zenodo.org/record/16514), (which has been published in Zenodo), and preprocess it. The preprocessing again consists on aggregating the four load-related eyetracking metrics into 10-second episodes, using a rolling window with 5-second slide between windows. Then, that aggregated data is merged with the video codes generated by researchers, regarding the social level, teacher activity and gaze focus (during the 10-second episodes where all eyetracking metrics agreed on high/low values). 

```{r, message=FALSE, warning=FALSE, echo=FALSE}
library(ggplot2)
# We load the useful scripts and packages needed throughout the report
source("./lib/rollingWindows.R")
source("./lib/loadIndex.R")
source("./lib/extremeLoadExtraction.R")
source("./lib/aggregateEpisodeData.R")
source("./lib/multiplot.R")
source("./lib/outliers.R")

# Create the directory structure onto which download the data
rootdir <- getwd()
datadir <- paste(rootdir,"data","study2",sep=.Platform$file.sep)
if(!dir.exists(datadir)) dir.create(datadir, recursive=T)
setwd(datadir)

# We download the data
if(!file.exists("DELANA-VideoCodingData.zip") || !file.exists("DELANA-EyetrackingData.zip")){
    download.file("https://zenodo.org/record/16514/files/DELANA-VideoCodingData.zip", destfile="DELANA-VideoCodingData.zip", method="curl")
    unzip("DELANA-VideoCodingData.zip")
    download.file("https://zenodo.org/record/16514/files/DELANA-EyetrackingData.zip", destfile="DELANA-EyetrackingData.zip", method="curl")
    unzip("DELANA-EyetrackingData.zip")
} 

# Now we have the raw data files uncompressed in the data/study2 folder

sessions <-  c("DELANA-Session1-Expert-eyetracking","DELANA-Session2-Expert-eyetracking","DELANA-Session3-Novice-eyetracking")

totaldata <- data.frame()
cleandatafile <- "study2ProcessedData.Rda"
if(!file.exists(cleandatafile)){
    data <- aggregateEpisodeData(sessions, datadir=datadir, initendtimes=NULL, SEPARATOR=";") # For this study the raw data is semicolon-separated, for the fix/sac at least!
    data <- data[,c(1:5,12)] # We select only the load-related metrics
    # We load and add the video coding data with the social, activity and main gaze focus dimensions
    videocodes <- read.csv("DELANA-videocoding.csv", sep=",")
    videocodes$session <- videocodes$Session
    totaldata <- merge(data,videocodes,by=c("session","time"),all=T)
    save(totaldata, file=cleandatafile)
}else{
  totaldata <- get(load(file=cleandatafile))
}


# We crop outliers in the saccade speed. They tend to throw off the HMM and PCA calculations
#countOutliers(totaldata$value.Sac,coef = 5, method="iqr") # 5xinter-quartile range
totaldata$value.Sac <- replaceOutliers(totaldata$value.Sac,valueNA = F,coef = 5, method="iqr")

loaddata <- calculateCoarseFineLoadIndex(totaldata,3:6,normalize=T) # We ensure that the values are normalized for those of the first window in which little load is assumed (just putting the eyetracker on)
#str(loaddata)
#names(loaddata)


# We assume that the teacher load in the expert sessions (1,2) is lower than in the novice sessions (session 3)
loaddata$TeacherLoad <- ifelse(loaddata$session==sessions[3],1,0)
# table(loaddata$TeacherLoad,loaddata$Activity)
# table(loaddata$TeacherLoad,loaddata$Social)
# table(loaddata$TeacherLoad,loaddata$Focus)
dataexpert <- loaddata[loaddata$TeacherLoad==0,]
datanovice <- loaddata[loaddata$TeacherLoad==1,]

```

Aside from those variables in Study 1, we have another "assumed ground truth" variable (`TeacherLoad`), which associates the **Expert teacher** sessions with *lower* loads and the **Novice teacher** sessions with *higher* loads.


## Calculate the PCA Load index

... from the eyetracking metrics, normalized by the value of the first three 10-s windows, to account for variations in the day's data (e.g., due to tiredness, etc.)

```{r, message=FALSE, warning=FALSE, echo=FALSE}

# We calculate the PCA load index (separately for the expert and novice teacher)
library(FactoMineR)

res.pca.norm = PCA(dataexpert[, c(14,17,20,23)], scale.unit=TRUE, ncp=5, graph=F)
plot.PCA(res.pca.norm, axes=c(1, 2), choix="var", title="PCA Expert, Normalized data, dims 1/2")
dataexpert$PCALoad = res.pca.norm$ind$coord[,1]

res.pca.norm = PCA(datanovice[, c(14,17,20,23)], scale.unit=TRUE, ncp=5, graph=F)
plot.PCA(res.pca.norm, axes=c(1, 2), choix="var", title="PCA Novice, Normalized data, dims 1/2")
datanovice$PCALoad = res.pca.norm$ind$coord[,1]

loaddata <- rbind(dataexpert,datanovice)

# We plot the loads for each session, along with some smoothing
for(session in sessions){
    sessiondata <- loaddata[loaddata$session==session,]
    p1 <- ggplot(sessiondata, aes(x=time/60000, y=PCALoad, col=PCALoad)) + 
            ggtitle(paste("PCA Load Index ",session,sep="")) + 
            geom_line(size=1) + stat_smooth(method="loess",span=0.1,se=F) +
            #theme(axis.text.x = element_text(size=18),plot.title=element_text(size=20, face="bold"),axis.title=element_text(size=18),panel.background = element_rect(fill = 'white')) +
            theme(panel.background = element_rect(fill = 'white')) +
            scale_color_gradient(low="green",high="red")
    print(p1)

}

```


## Validation of the PCA Load measure

That is: Can this PCA Load index help us distinguish between expert teacher sessions and novice teacher sessions? Or, put another way, is the PCA Load index different, once we remove the effect of the other process variables (teacher activity, social plane of interaction, main focus of the gaze)


To do so, we train a logistic regression model that tries to predict the "teacher expertise condition" on the basis of the PCA Load index and the orchestration process variables coded by a human:

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}

behdata <- loaddata[!is.na(loaddata$Activity) & !is.na(loaddata$Social) & !is.na(loaddata$Focus),]

# We remove the levels for which we do not have enough data
behdata <- behdata[behdata$Social!="GRP",]
behdata$Social <- factor(behdata$Social)
behdata <- behdata[behdata$Focus!="BAK",]
behdata <- behdata[behdata$Focus!="TAB",]
behdata <- behdata[behdata$Focus!="TEA",]
behdata$Focus <- factor(behdata$Focus)



# We train the logistic regression model
# lr1 <- glm(TeacherLoad ~ Activity + Social + Focus + PCALoad, family=binomial(link='logit'), data=behdata)
# summary(lr1)
# anova(lr1, test="Chisq")
library(caret)
set.seed(1)
Train <- createDataPartition(behdata$TeacherLoad, p=0.7, list=FALSE)
training <- behdata[ Train, ]
testing <- behdata[ -Train, ]
#mod_fit <- train(TeacherLoad ~ Activity + Social + Focus + PCALoad,  
#                 data=training, method="glm", family="binomial")

mod_fit <- glm(TeacherLoad ~ Activity + Social + Focus + PCALoad, 
                   data=training, family="binomial")
mod_fit_base <- glm(TeacherLoad ~ Activity + Social + Focus, 
                   data=training, family="binomial")

# Compare the model with PCA load with the model without it
print("ANOVA of logistic regression models with and without the PCA Load as a variable")
anova(mod_fit_base, mod_fit, test ="Chisq")

# McFadden's pseudo-Rsquared, to get an idea of the proportion of variance explained
library(pscl)
print("McFadden's pseudo Rsquared, base model WITHOUT PCA Load")
pR2(mod_fit_base)["McFadden"]  # look for 'McFadden', 0.34
print("McFadden's pseudo Rsquared, model WITH PCA Load")
pR2(mod_fit)["McFadden"]  # look for 'McFadden', 0.43

# Wald test for individual predictors
library(survey)
#regTermTest(mod_fit, "Activity")
#regTermTest(mod_fit, "Social") # p=0.004, removing this variable would harm substantially the fit of the model
#regTermTest(mod_fit, "Focus")
print("Wald test: would removing the PCA Load harm the model fit")
regTermTest(mod_fit, "PCALoad") # p=0.002, removing this variable would harm substantially the fit of the model

# Variable importance
print("Variable importance")
varImp(mod_fit) # PCALoad is the most important variable

# Predictions and accuracy of the model (as a curiosity)
# ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE)
# mod_fit <- train(TeacherLoad ~ Activity + Social + Focus + PCALoad,  data=training,
#                  method="glm", family="binomial", trControl = ctrl, tuneLength = 5)
# mod_base <- train(TeacherLoad ~ Activity + Social + Focus,  data=training,
#                  method="glm", family="binomial", trControl = ctrl, tuneLength = 5)
# pred = predict(mod_fit, newdata=testing)
# predbase = predict(mod_base, newdata=testing)
# eval = data.frame(cutoff=seq(from=0, to=1, length.out=100))
# eval$base = NA
# eval$model = NA
# for(i in 1:nrow(eval)){
#     eval[i,"model"] <- confusionMatrix(data=ifelse(pred>eval$cutoff[i],1,0), testing$TeacherLoad)$overall["Accuracy"]
#     eval[i,"base"] <- confusionMatrix(data=ifelse(predbase>eval$cutoff[i],1,0), testing$TeacherLoad)$overall["Accuracy"]
# }
# ggplot(eval, aes(x=cutoff, y=model))+geom_line()+geom_line(aes(y=base), col="red")
# max(eval$model) # Max accuracy, 93%
# max(eval$base) # Max accuracy, 91%

```



## Orchestration load patterns (linear model)


To get an idea of how the PCA load index is related to the different kinds of classroom episodes, in terms of the orchestration dimensions coded by a human researcher (teacher activity, social plane of interaction and main focus of the teacher gaze), we can produce a linear model for the expert teacher and another one for the novice:

**Expert teacher**

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}

# Expert teacher
behexpert <- dataexpert[!is.na(dataexpert$Activity) & !is.na(dataexpert$Social) & !is.na(dataexpert$Focus),]

#ggplot(behexpert,aes(x=PCALoad))+geom_density()
# The distribution of coded values goes continuouosly along the dimension, so we do a linear model

# Optional: delete the factor values with too few occurrences?
behexpert$Social <- factor(behexpert$Social)
behexpert <- behexpert[behexpert$Focus!="BAK",]
behexpert <- behexpert[behexpert$Focus!="SCOMP",]
behexpert <- behexpert[behexpert$Focus!="TAB",]
behexpert <- behexpert[behexpert$Focus!="TEA",]
behexpert$Focus <- factor(behexpert$Focus)

lmexp <- lm(PCALoad ~ Activity + Social + Focus, data = behexpert)
summary(lmexp)
anova(lmexp, test="Chisq")
```

We observe that, for these episodes coded, a simple linear model of the three orchestration dimensions explains 13% of the variance in PCA Load Index. In this case we see that the social level and the focus of the gaze are significant contributors to the predictor model, most notably through the TeacherCOMPuter focus (which is on average much lower PCA load than the intercept -- the student faces).

**Novice teacher**

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}

# Novice teacher
behnovice <- datanovice[!is.na(datanovice$Activity) & !is.na(datanovice$Social) & !is.na(datanovice$Focus),]

#ggplot(behnovice,aes(x=PCALoad))+geom_density()
# The distribution of coded values goes continuouosly along the dimension, so we do a linear model

# Optional: delete the factor values with too few occurrences?
behnovice <- behnovice[behnovice$Activity!="QUEST",]
behnovice <- behnovice[behnovice$Activity!="TDT",]
behnovice$Activity <- factor(behnovice$Activity)
behnovice <- behnovice[behnovice$Social!="GRP",]
behnovice$Social <- factor(behnovice$Social)
behnovice <- behnovice[behnovice$Focus!="BAK",]
behnovice <- behnovice[behnovice$Focus!="PROJ",]
behnovice <- behnovice[behnovice$Focus!="TAB",]
behnovice <- behnovice[behnovice$Focus!="TEA",]
behnovice <- behnovice[behnovice$Focus!="WHIT",]
behnovice$Focus <- factor(behnovice$Focus)

lmnov <- lm(PCALoad ~ Activity + Social + Focus, data = behnovice)
summary(lmnov)
anova(lmnov, test="Chisq")
```

We observe that, for these episodes coded, a simple linear model of the three orchestration dimensions explains 6% of the variance in PCA Load Index. In this case we see that predictor linear model is not a good predictor (e.g., not even its p-value is significantly better than a constant predictor). The most probable explanation for this is that there is not enough data for this teacher to see clear trends (only one session recorded, vs. two for the expert teacher, or three in study 1).




```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}

# We go back to the root directory for the next study's scripts
setwd(rootdir)
```

