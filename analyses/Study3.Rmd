---
title: "Study3"
author: "lprisan"
date: "April 13, 2016"
output: html_document
---

(add some contextual info from the paper)

As a first step, we download the two datasets for Study 3 ([baseline](https://zenodo.org/record/16551/) and [novel technology]()), (which have been published in Zenodo), and preprocess it. The preprocessing again consists on aggregating the four load-related eyetracking metrics into 10-second episodes, using a rolling window with 5-second slide between windows. Then, that aggregated data is merged with the video codes generated by researchers, regarding the social level, teacher activity and gaze focus (during the 10-second episodes where all eyetracking metrics agreed on high/low values). 

```{r, message=FALSE, warning=FALSE, echo=FALSE}
library(ggplot2)
# We load the useful scripts and packages needed throughout the report
source("./lib/rollingWindows.R")
source("./lib/loadIndex.R")
source("./lib/extremeLoadExtraction.R")
source("./lib/aggregateEpisodeData.R")
source("./lib/multiplot.R")
source("./lib/outliers.R")

# Create the directory structure onto which download the data
rootdir <- getwd()
datadir <- paste(rootdir,"data","study3",sep=.Platform$file.sep)
if(!dir.exists(datadir)) dir.create(datadir, recursive=T)
setwd(datadir)

# We download and uncompress the data
if(!file.exists("ISL2014BASELINE-QuestionnaireData.zip") ||
   !file.exists("ISL2015BASELINE-CodingData.zip") ||
   !file.exists("ISL2014BASELINE-EyetrackingData.zip") ||
   !file.exists("ISL2015NOVEL-CodingData.zip") ||
   !file.exists("ISL2015NOVEL-EyetrackingData.zip") ||
   !file.exists("ISL2015NOVEL-QuestionnaireData.zip")){ 
    download.file("https://zenodo.org/record/16551/files/ISL2014BASELINE-QuestionnaireData.zip", destfile="ISL2014BASELINE-QuestionnaireData.zip", method="curl")
    unzip("ISL2014BASELINE-QuestionnaireData.zip")
    download.file("https://zenodo.org/record/16551/files/ISL2015BASELINE-CodingData.zip", destfile="ISL2015BASELINE-CodingData.zip", method="curl")
    unzip("ISL2015BASELINE-CodingData.zip")
    download.file("https://zenodo.org/record/16551/files/ISL2014BASELINE-EyetrackingData.zip", destfile="ISL2014BASELINE-EyetrackingData.zip", method="curl")
    unzip("ISL2014BASELINE-EyetrackingData.zip")
    
    #TODO: Download the data once the data for ISL2015 is in zenodo
    unzip("ISL2015NOVEL-CodingData.zip")
    unzip("ISL2015NOVEL-EyetrackingData.zip")
    unzip("ISL2015NOVEL-QuestionnaireData.zip")
} 

# Now we have the raw data files uncompressed in the data/study3 folder

sessions <-  c("ISL2014BASELINE-Session1-eyetracking","ISL2014BASELINE-Session2-eyetracking","ISL2015NOVEL-Session3-eyetracking","ISL2015NOVEL-Session4-eyetracking")

totaldata <- data.frame()
cleandatafile <- "study3ProcessedData.Rda"
if(!file.exists(cleandatafile)){

    data <- aggregateEpisodeData(sessions, datadir=datadir, initendtimes=NULL, SEPARATOR=";") # For this study the raw data is semicolon-separated, at least the fixation/saccades!
    data <- data[,c(1:5,12)] # We select only the load-related metrics
    # We load and add the video coding data with the social, activity and main gaze focus dimensions
    # clean and put all videocoding data into a single file
    videocodes1 <- read.csv("ISL2014BASELINE-videocoding.csv", sep=",")
    videocodes1$session <- videocodes1$Session
    snippets1 <- read.csv("ISL2014BASELINE-stimulatedrecall-snippetselection.csv", sep=",")
    ratings1 <- read.csv("ISL2014BASELINE-stimulatedrecall-ratings.csv", sep=",")
    srdata1 <- merge(snippets1, ratings1, by=c("Session", "Snippet"),all=T)
    audiocodes1 <- read.csv("ISL2014BASELINE-stimulatedrecall-audiocoding.csv", sep=";")
    audiocodes1$time <- audiocodes1$Eyetrack.Time
    srdata1$time <- srdata1$Window.Center
    srdata1 <- merge(srdata1,audiocodes1,by=c("Session","time","Snippet"),all=T)
    srdata1$session <- srdata1$Session
    srdata1 <- srdata1[,c(2,3,6,8,9,10,13)] # We keep only non-duplicated, useful columns

    videocodes2 <- read.csv("ISL2015NOVEL-videocoding.csv", sep=",")[,-9]
    videocodes2$session <- videocodes2$Session
    snippets2 <- read.csv("ISL2015NOVEL-stimulatedrecall-snippetselection.csv", sep=",")
    ratings2 <- read.csv("ISL2015NOVEL-stimulatedrecall-ratings.csv", sep=",")
    srdata2 <- merge(snippets2, ratings2, by=c("Session", "Snippet"),all=T)
    audiocodes2 <- read.csv("ISL2015NOVEL-stimulatedrecall-audiocoding.csv", sep=";")[1:32,]
    audiocodes2$time <- audiocodes2$Eyetrack.Time
    srdata2$time <- srdata2$Window.Center
    srdata2 <- merge(srdata2,audiocodes2,by=c("Session","time","Snippet"),all=T)
    srdata2$session <- srdata2$Session
    srdata2 <- srdata2[,c(2,3,6,8,9,10,13)] # We keep only non-duplicated, useful columns
    
    videocodes <- rbind(videocodes1,videocodes2)
    srdata <- rbind(srdata1,srdata2)
    totaldata <- merge(data,videocodes,by=c("session","time"),all=T)
    totaldata <- merge(totaldata,srdata,by=c("session","time"),all=T)
    save(totaldata, file=cleandatafile)
    
    
    
}else{
  totaldata <- get(load(file=cleandatafile))
}

# Remove missing values
totaldata <- totaldata[!is.na(totaldata$value.Sac),]
# We crop outliers in the saccade speed. They tend to throw off the HMM and PCA calculations
#countOutliers(totaldata$value.Sac,coef = 5, method="iqr") # 5xinter-quartile range
totaldata$value.Sac <- replaceOutliers(totaldata$value.Sac,valueNA = F,coef = 5, method="iqr")

loaddata <- calculateCoarseFineLoadIndex(totaldata,3:6,normalize=T) # We ensure that the values are normalized for those of the first window in which little load is assumed (just putting the eyetracker on)
#str(loaddata)
#names(loaddata)


# We assume that the teacher load in the usual technology/baseline sessions (1,2) is lower than in the novel technology sessions (3, 4)
loaddata$TeacherLoad <- ifelse(loaddata$session==sessions[3] | loaddata$session==sessions[4],1,0)

# We do not separate the data yet -- the PCA is calculated per teacher, and here we only have 1 teacher
#datausual <- loaddata[loaddata$TeacherLoad==0,]
#datanovel <- loaddata[loaddata$TeacherLoad==1,]

```

Aside from those variables in Study 1, we have another "assumed ground truth" variable (`TeacherLoad`), which associates the **Sessions using the usual technology** sessions with *lower* loads, and the **Novel technology** sessions with *higher* loads.



## Calculate the PCA Load index

... from the eyetracking metrics, normalized by the value of the first three 10-s windows, to account for variations in the day's data (e.g., due to tiredness, etc.)

```{r, message=FALSE, warning=FALSE, echo=FALSE}

# We calculate the PCA load index (separately for the expert and novice teacher)
library(FactoMineR)

res.pca.norm = PCA(loaddata[, c(19,22,25,28)], scale.unit=TRUE, ncp=5, graph=F)
plot.PCA(res.pca.norm, axes=c(1, 2), choix="var", title="PCA All sessions, Normalized data, dims 1/2")
loaddata$PCALoad = res.pca.norm$ind$coord[,1]

# In case we wanted to calculate the PCA separately
# res.pca.norm = PCA(datausual[, c(19,22,25,28)], scale.unit=TRUE, ncp=5, graph=F)
# plot.PCA(res.pca.norm, axes=c(1, 2), choix="var", title="PCA Usual tech, Normalized data, dims 1/2")
# datausual$PCALoad = res.pca.norm$ind$coord[,1]
# res.pca.norm = PCA(datanovel[, c(19,22,25,28)], scale.unit=TRUE, ncp=5, graph=F)
# plot.PCA(res.pca.norm, axes=c(1, 2), choix="var", title="PCA Novel tech, Normalized data, dims 1/2")
# datanovel$PCALoad = res.pca.norm$ind$coord[,1]
# loaddata <- rbind(datausual,datanovel)

# We plot the loads for each session, along with some smoothing
for(session in sessions){
    sessiondata <- loaddata[loaddata$session==session,]
    p1 <- ggplot(sessiondata, aes(x=time/60000, y=PCALoad, col=PCALoad)) + 
            ggtitle(paste("PCA Load Index ",session,sep="")) + 
            geom_line(size=1) + stat_smooth(method="loess",span=0.1,se=F) +
            #theme(axis.text.x = element_text(size=18),plot.title=element_text(size=20, face="bold"),axis.title=element_text(size=18),panel.background = element_rect(fill = 'white')) +
            theme(panel.background = element_rect(fill = 'white')) +
            scale_color_gradient(low="green",high="red")
    print(p1)

}

```


## Validation of the PCA Load measure

That is: Can this PCA Load index help us distinguish between sessions using the usual and a novel technology? Or, put another way, is the PCA Load index different, once we remove the effect of the other process variables (teacher activity, social plane of interaction, main focus of the gaze)


To do so, we train a logistic regression model that tries to predict the "technology used condition" on the basis of the PCA Load index and the orchestration process variables coded by a human:

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}

behdata <- loaddata[!is.na(loaddata$Activity) & !is.na(loaddata$Social) & !is.na(loaddata$Focus),]

# table(behdata$TeacherLoad,behdata$Activity)
# table(behdata$TeacherLoad,behdata$Social)
# table(behdata$TeacherLoad,behdata$Focus)

# We remove the levels for which we do not have enough data
behdata <- behdata[behdata$Activity!="DISC",]
behdata <- behdata[behdata$Activity!="OFF",]
behdata <- behdata[behdata$Activity!="TEC",]
behdata$Activity <- factor(behdata$Activity)
behdata <- behdata[behdata$Focus!="BAK",]
behdata <- behdata[behdata$Focus!="CHR",]
behdata <- behdata[behdata$Focus!="RES",]
behdata <- behdata[behdata$Focus!="TNG",]
behdata <- behdata[behdata$Focus!="TPAP",]
behdata$Focus <- factor(behdata$Focus)

# We train the logistic regression model
lr1 <- glm(TeacherLoad ~ Activity + Social + Focus + PCALoad, family=binomial(link='logit'), data=behdata)
summary(lr1)
anova(lr1, test="Chisq")
library(caret)
set.seed(1)
Train <- createDataPartition(behdata$TeacherLoad, p=0.7, list=FALSE)
training <- behdata[ Train, ]
testing <- behdata[ -Train, ]
#mod_fit <- train(TeacherLoad ~ Activity + Social + Focus + PCALoad,  
#                 data=training, method="glm", family="binomial")

mod_fit <- glm(TeacherLoad ~ Activity + Social + Focus + PCALoad, 
                   data=training, family="binomial")
mod_fit_base <- glm(TeacherLoad ~ Activity + Social + Focus, 
                   data=training, family="binomial")

# Compare the model with PCA load with the model without it
print("ANOVA of logistic regression models with and without the PCA Load as a variable")
anova(mod_fit_base, mod_fit, test ="Chisq")

# McFadden's pseudo-Rsquared, to get an idea of the proportion of variance explained
library(pscl)
print("McFadden's pseudo Rsquared, base model WITHOUT PCA Load")
pR2(mod_fit_base)["McFadden"]  # look for 'McFadden', 0.71
print("McFadden's pseudo Rsquared, model WITH PCA Load")
pR2(mod_fit)["McFadden"]  # look for 'McFadden', 0.88

# Wald test for individual predictors
library(survey)
#regTermTest(mod_fit, "Activity") # p=0.03, removing this variable would harm substantially the fit of the model
#regTermTest(mod_fit, "Social") # p=0.001, removing this variable would harm substantially the fit of the model
#regTermTest(mod_fit, "Focus")
print("Wald test: would removing the PCA Load harm the model fit")
regTermTest(mod_fit, "PCALoad") # p=0.00002, removing this variable would harm substantially the fit of the model

# Variable importance
print("Variable importance")
varImp(mod_fit) # PCALoad is the most important variable

# Predictions and accuracy of the model (as a curiosity)
# ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE)
# mod_fit <- train(TeacherLoad ~ Activity + Social + Focus + PCALoad,  data=training,
#                  method="glm", family="binomial", trControl = ctrl, tuneLength = 5)
# mod_base <- train(TeacherLoad ~ Activity + Social + Focus,  data=training,
#                  method="glm", family="binomial", trControl = ctrl, tuneLength = 5)
# pred = predict(mod_fit, newdata=testing)
# predbase = predict(mod_base, newdata=testing)
# eval = data.frame(cutoff=seq(from=0, to=1, length.out=100))
# eval$base = NA
# eval$model = NA
# for(i in 1:nrow(eval)){
#     eval[i,"model"] <- confusionMatrix(data=ifelse(pred>eval$cutoff[i],1,0), testing$TeacherLoad)$overall["Accuracy"]
#     eval[i,"base"] <- confusionMatrix(data=ifelse(predbase>eval$cutoff[i],1,0), testing$TeacherLoad)$overall["Accuracy"]
# }
# ggplot(eval, aes(x=cutoff, y=model))+geom_line()+geom_line(aes(y=base), col="red")
# max(eval$model) # Max accuracy, 96%
# max(eval$base) # Max accuracy, 93%

```

We observe that not only the PCALoad is a significant predictor of the assumed ground truth variable, it is actually the most important variable in the model, even more so than the other process variables (activity, social & focus).


## Orchestration load patterns (linear model)


To get an idea of how the PCA load index is related to the different kinds of classroom episodes, in terms of the orchestration dimensions coded by a human researcher (teacher activity, social plane of interaction and main focus of the teacher gaze), we can produce a linear model of the PCA-calculated load for the teacher, overall, and separately for each kind of session (since they are quite different in terms of the process variables coded by humans).

**Overall trends**

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}

# Overall
#ggplot(behdata,aes(x=PCALoad))+geom_density()
# The distribution of coded values goes continuouosly along the dimension, so we do a linear model

lmall <- lm(PCALoad ~ Activity + Social + Focus, data = behdata)
summary(lmall)
anova(lmall, test="Chisq")
```

We observe that, for these episodes coded, a simple linear model of the three orchestration dimensions explains 23% of the variance in PCA Load Index. In this case we see that the teaching activity, the social level and the focus of the gaze are significant contributors to the predictor model, most notably through the QUESTioning activity (higher PCA load) and TDTransition activity (lower PCA load). Also, GRP and INDividual interactions are lower PCA load, and so are the episodes in which the teacher focuses on the PRJector.


**Usual technology sessions**

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}

# usual tech
behusual <- behdata[behdata$TeacherLoad==0,]

#ggplot(behusual,aes(x=PCALoad))+geom_density()
# The distribution of coded values goes continuouosly along the dimension, so we do a linear model

# Optional: delete the factor values with too few occurrences?
behusual <- behusual[behusual$Social!="GRP",]
behusual$Social <- factor(behusual$Social)
behusual <- behusual[behusual$Focus!="PRJ",]
behusual <- behusual[behusual$Focus!="TAB",]
behusual$Focus <- factor(behusual$Focus)

lmusu <- lm(PCALoad ~ Activity + Social + Focus, data = behusual)
summary(lmusu)
anova(lmusu, test="Chisq")
```

We observe that, in this more specific model, a simple linear model of the three orchestration dimensions explains 30% of the variance in PCA Load Index. In this case we see that the activity and the social level are significant contributors to the predictor model, most notably through the intercept values (EXPlanations, at the CLSs level, looking at student faces) which tend to have high load values. Also, we find similar trends as in the overall model (TDTranstitions and INDividual interaction being low load, QUEstioning being higher load). Furthermore, episodes with a TeacherCOMPuter focus have on average lower PCA load than the intercept (the student faces).

**Novel technology sessions**

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}

# Novel tech
behnovel <- behdata[behdata$TeacherLoad==1,]

#ggplot(behnovel,aes(x=PCALoad))+geom_density()
# The distribution of coded values goes continuouosly along the dimension, so we do a linear model

# Optional: delete the factor values with no/too few occurrences?
behnovel <- behnovel[behnovel$Focus!="LAP",]
behnovel$Focus <- factor(behnovel$Focus)

lmnov <- lm(PCALoad ~ Activity + Social + Focus, data = behnovel)
summary(lmnov)
anova(lmnov, test="Chisq")
```

Interestingly, the model of the novel technology sessions has a distinctive bimodal distribution, and the linear model taking both sessions into account have a very low predictive value (adjusted Rsquared close to zero). This indicates that maybe the two novel technology sessions were so different from each other that a common model does not make sense. Indeed, according to the observations, the teacher had a less active role in the first novel tech session (leaving the lead to the researcher), being much more active in the second novel tech session.

**Novel tech session 1 (teacher acting as co-orchestrator)**

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}

# Novel tech 1
behnovel1 <- behnovel[behnovel$session==sessions[3],]

# Optional: Remove values with low count of episodes
#behnovel1 <- behnovel1[behnovel1$Activity!="EXP",]
behnovel1 <- behnovel1[behnovel1$Activity!="QUE",]
behnovel1$Activity <- factor(behnovel1$Activity)

#ggplot(behnovel1,aes(x=PCALoad))+geom_density()
# The distribution of coded values goes continuouosly along the dimension, so we do a linear model

lmnov1 <- lm(PCALoad ~ Activity + Social + Focus, data = behnovel1)
summary(lmnov1)
anova(lmnov1, test="Chisq")
```

Despite the low volume of data to build the model (only 63 episodes coded), the model of the first novel technology session has a reasonable predictive power (explains 30% of the variance in PCA load). The most significant contributor to this model is the teaching activity (EXPlanations being high load, and all other activities being on average lower load than that).

**Novel tech session 2 (teacher acting main orchestrator)**

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}

# Novel tech 2
behnovel2 <- behnovel[behnovel$session==sessions[4],]

# Optional: Remove values with low count of episodes
behnovel2 <- behnovel2[behnovel2$Focus!="TCOMP",]
behnovel2$Focus <- factor(behnovel2$Focus)

#ggplot(behnovel2,aes(x=PCALoad))+geom_density()
# The distribution of coded values goes continuouosly along the dimension, so we do a linear model

lmnov2 <- lm(PCALoad ~ Activity + Social + Focus, data = behnovel2)
summary(lmnov2)
anova(lmnov2, test="Chisq")
```

Despite the low volume of data to build the model (only 100 episodes coded), the model of the second novel technology session has a reasonable predictive power (explains 24% of the variance in PCA load). The most significant contributor to this model is the social level and the focus of the gaze, with INDividual interactions being notably lower, and looking at the TABletop interface being notably higher load than the intercept value (CLSs level interaction and looking at student FACes).




## Appendix: Using Factor analysis instead of PCA load index

... results are largely the same, even if some of the coefficient estimations are different. The first factor is the most important predictor of the logistic regression model, and the linear model of process variables explains a 41% of the variance in factor analysis load, and the trends are largely equal (although with different significance levels).

```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}

library(psych)

#Expert
X <- loaddata[, c(19,22,25,28)]
N <- nrow(loaddata[, c(19,22,25,28)])
corMat <- cor(X)
faPC  <- fa(r=corMat, nfactors=1, n.obs=N, rotate="varimax")
bartlett <- factor.scores(x=X, f=faPC, method="Bartlett")
loaddata$FALoad <- bartlett$scores[,1]
# factor.plot(faPC, cut=0.3)
# fa.diagram(faPC)
# fa.parallel(X)
# vss(X, n.obs=N, rotate="varimax")

behdata <- loaddata[!is.na(loaddata$Activity) & !is.na(loaddata$Social) & !is.na(loaddata$Focus),]

# We remove the levels for which we do not have enough data
behdata <- behdata[behdata$Activity!="DISC",]
behdata <- behdata[behdata$Activity!="OFF",]
behdata <- behdata[behdata$Activity!="TEC",]
behdata$Activity <- factor(behdata$Activity)
behdata <- behdata[behdata$Focus!="BAK",]
behdata <- behdata[behdata$Focus!="CHR",]
behdata <- behdata[behdata$Focus!="RES",]
behdata <- behdata[behdata$Focus!="TNG",]
behdata <- behdata[behdata$Focus!="TPAP",]
behdata$Focus <- factor(behdata$Focus)


library(caret)
set.seed(1)
Train <- createDataPartition(behdata$TeacherLoad, p=0.7, list=FALSE)
training <- behdata[ Train, ]
testing <- behdata[ -Train, ]
#mod_fit <- train(TeacherLoad ~ Activity + Social + Focus + FALoad,  
#                 data=training, method="glm", family="binomial")
mod_fit <- glm(TeacherLoad ~ Activity + Social + Focus + FALoad, 
                   data=training, family="binomial")
mod_fit_base <- glm(TeacherLoad ~ Activity + Social + Focus, 
                   data=training, family="binomial")
# Compare the model with FA load with the model without it
print("ANOVA of logistic regression models with and without the FA Load as a variable")
anova(mod_fit_base, mod_fit, test ="Chisq")
# McFadden's pseudo-Rsquared, to get an idea of the proportion of variance explained
library(pscl)
print("McFadden's pseudo Rsquared, base model WITHOUT FA Load")
pR2(mod_fit_base)["McFadden"]  # look for 'McFadden', 0.71
print("McFadden's pseudo Rsquared, model WITH FA Load")
pR2(mod_fit)["McFadden"]  # look for 'McFadden', 0.90
# Wald test for individual predictors
library(survey)
#regTermTest(mod_fit, "Activity")
#regTermTest(mod_fit, "Social") # p=0.0007, removing this variable would harm substantially the fit of the model
#regTermTest(mod_fit, "Focus") # p=0.03, removing this variable would harm substantially the fit of the model
print("Wald test: would removing the FA Load harm the model fit")
regTermTest(mod_fit, "FALoad") # p=0.0008, , removing this variable would harm substantially the fit of the model
# Variable importance
print("Variable importance")
varImp(mod_fit) # FALoad is the most important variable

# What about the orchestration patterns? (linear models)

# Overall 
#ggplot(behdata,aes(x=FALoad))+geom_density()
# The distribution of coded values goes continuouosly along the dimension, so we do a linear model
lmall <- lm(FALoad ~ Activity + Social + Focus, data = behdata)
summary(lmall)
anova(lmall, test="Chisq")

# Usual tech sessions
behusual <- behdata[behdata$TeacherLoad==0,]
#ggplot(behusual,aes(x=FALoad))+geom_density()
# The distribution of coded values goes continuouosly along the dimension, so we do a linear model
# Optional: delete the factor values with too few occurrences?
behusual <- behusual[behusual$Social!="GRP",]
behusual$Social <- factor(behusual$Social)
behusual <- behusual[behusual$Focus!="PRJ",]
behusual <- behusual[behusual$Focus!="TAB",]
behusual$Focus <- factor(behusual$Focus)
lmusu <- lm(FALoad ~ Activity + Social + Focus, data = behusual)
summary(lmusu)
anova(lmusu, test="Chisq")

# Novel tech sessions
behnovel <- behdata[behdata$TeacherLoad==1,]
#ggplot(behnovel,aes(x=FALoad))+geom_density()
# The distribution of coded values goes continuouosly along the dimension, so we do a linear model
# Optional: delete the factor values with no/too few occurrences?
behnovel <- behnovel[behnovel$Focus!="LAP",]
behnovel$Focus <- factor(behnovel$Focus)
lmnov <- lm(FALoad ~ Activity + Social + Focus, data = behnovel)
summary(lmnov)
anova(lmnov, test="Chisq")

# Novel tech 1
behnovel1 <- behnovel[behnovel$session==sessions[3],]
# Optional: Remove values with low count of episodes
#behnovel1 <- behnovel1[behnovel1$Activity!="EXP",]
behnovel1 <- behnovel1[behnovel1$Activity!="QUE",]
behnovel1$Activity <- factor(behnovel1$Activity)
#ggplot(behnovel1,aes(x=FALoad))+geom_density()
# The distribution of coded values goes continuouosly along the dimension, so we do a linear model
lmnov1 <- lm(FALoad ~ Activity + Social + Focus, data = behnovel1)
summary(lmnov1)
anova(lmnov1, test="Chisq")

# Novel tech 2
behnovel2 <- behnovel[behnovel$session==sessions[4],]
# Optional: Remove values with low count of episodes
behnovel2 <- behnovel2[behnovel2$Focus!="TCOMP",]
behnovel2$Focus <- factor(behnovel2$Focus)
#ggplot(behnovel2,aes(x=FALoad))+geom_density()
# The distribution of coded values goes continuouosly along the dimension, so we do a linear model
lmnov2 <- lm(FALoad ~ Activity + Social + Focus, data = behnovel2)
summary(lmnov2)
anova(lmnov2, test="Chisq")

```





***



```{r, cache=FALSE, message=FALSE, warning=FALSE, echo=FALSE}

# We go back to the root directory for the next study's scripts
setwd(rootdir)
```


